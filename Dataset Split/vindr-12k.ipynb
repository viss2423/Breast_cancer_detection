{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "zip_file_path = 'D:\\\\Python files\\\\yolo_breast_cancer\\\\vindr-mammo-a-large-scale-benchmark-dataset-for-computer-aided-detection-and-diagnosis-in-full-field-digital-mammography-1.0.0.zip'\n",
    "\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    file_list = zip_ref.namelist()\n",
    "\n",
    "# List the folders and files\n",
    "folders = set()\n",
    "for file in file_list:\n",
    "    components = file.split('/')\n",
    "    if len(components) > 1:\n",
    "        folders.add(components[0])\n",
    "\n",
    "print(\"Folders in the zip file:\")\n",
    "for folder in folders:\n",
    "    print(folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "zip_file_path = 'D:\\\\Python files\\\\yolo_breast_cancer\\\\vindr-mammo-a-large-scale-benchmark-dataset-for-computer-aided-detection-and-diagnosis-in-full-field-digital-mammography-1.0.0.zip'\n",
    "target_folder = 'vindr-mammo-a-large-scale-benchmark-dataset-for-computer-aided-detection-and-diagnosis-in-full-field-digital-mammography-1.0.0'\n",
    "\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    file_list = zip_ref.namelist()\n",
    "\n",
    "# List the folders within the specified folder\n",
    "folders = set()\n",
    "for file in file_list:\n",
    "    if file.startswith(target_folder + '/'):\n",
    "        components = file[len(target_folder):].split('/')\n",
    "        if len(components) > 1:\n",
    "            folders.add(components[1])\n",
    "\n",
    "print(f\"Folders inside '{target_folder}' in the zip file:\")\n",
    "for folder in folders:\n",
    "    print(folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "zip_file_path = 'D:\\\\Python files\\\\yolo_breast_cancer\\\\vindr-mammo-a-large-scale-benchmark-dataset-for-computer-aided-detection-and-diagnosis-in-full-field-digital-mammography-1.0.0.zip'\n",
    "target_folder = 'vindr-mammo-a-large-scale-benchmark-dataset-for-computer-aided-detection-and-diagnosis-in-full-field-digital-mammography-1.0.0'\n",
    "csv_file_name = 'finding_annotations.csv'\n",
    "\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    # Check if the CSV file exists in the archive\n",
    "    if target_folder + '/' + csv_file_name in zip_ref.namelist():\n",
    "        with zip_ref.open(target_folder + '/' + csv_file_name) as file:\n",
    "            data_final = pd.read_csv(file)\n",
    "            print(f\"Contents of '{csv_file_name}':\")\n",
    "            print(data_final)\n",
    "    else:\n",
    "        print(f\"'{csv_file_name}' not found in the zip file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column \"classification\" based on \"breast_birads\"\n",
    "data_final['classification'] = data_final['breast_birads'].apply(lambda x: 'Malignant' if x in ['BI-RADS 4', 'BI-RADS 5'] else 'Benign')\n",
    "\n",
    "# Drop rows with \"BI-RADS 3\" in the \"breast_birads\" column\n",
    "data_final = data_final[data_final['breast_birads'] != 'BI-RADS 3']\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(data_final.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the total number of \"Malignant\" and \"Benign\" cases\n",
    "classification_counts = data_final['classification'].value_counts()\n",
    "print(classification_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your DataFrame is named 'data_final'\n",
    "negative_values_count = (data_final['xmin'] < 0).sum() + (data_final['xmax'] < 0).sum() + (data_final['ymin'] < 0).sum() + (data_final['ymax'] < 0).sum()\n",
    "\n",
    "# Display the total count of rows with negative values in 'xmin', 'xmax', 'ymin', and 'ymax'\n",
    "print(\"Total count of rows with negative values:\", negative_values_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your DataFrame is named 'data_final'\n",
    "negative_rows = data_final[(data_final['xmin'] < 0) | (data_final['xmax'] < 0) | (data_final['ymin'] < 0) | (data_final['ymax'] < 0)]\n",
    "\n",
    "# Display the study_id, image_id, xmin, xmax, ymin, and ymax of rows with negative values\n",
    "negative_values_df = negative_rows[['study_id', 'image_id', 'xmin', 'xmax', 'ymin', 'ymax']]\n",
    "print(\"DataFrame with rows containing negative values:\")\n",
    "print(negative_values_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pydicom\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Define the path to the ZIP file\n",
    "zip_file_path = 'D:\\\\Python files\\\\yolo_breast_cancer\\\\vindr-mammo-a-large-scale-benchmark-dataset-for-computer-aided-detection-and-diagnosis-in-full-field-digital-mammography-1.0.0.zip'\n",
    "\n",
    "# Function to load and display DICOM images with bounding boxes based on study_id and image_id\n",
    "def load_and_display_dicom_image_with_bbox(zip_file_path, study_id, image_id, xmin, ymin, xmax, ymax):\n",
    "    # Load the DICOM image from the ZIP file\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        with zip_ref.open(f'vindr-mammo-a-large-scale-benchmark-dataset-for-computer-aided-detection-and-diagnosis-in-full-field-digital-mammography-1.0.0/images/{study_id}/{image_id}.dicom') as file:\n",
    "            ds = pydicom.dcmread(file)\n",
    "\n",
    "    # Display the DICOM image with bounding box\n",
    "    plt.imshow(ds.pixel_array, cmap='gray')\n",
    "    plt.title(f'DICOM image from \"{image_id}.dicom\"')\n",
    "\n",
    "    # Overlay bounding box on the image\n",
    "    rect = patches.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, linewidth=1, edgecolor='r', facecolor='none')\n",
    "    plt.gca().add_patch(rect)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Display DICOM images with bounding boxes for each row in negative_values_df\n",
    "for index, row in negative_values_df.iterrows():\n",
    "    print(f\"Study ID: {row['study_id']}, Image ID: {row['image_id']}\")\n",
    "    load_and_display_dicom_image_with_bbox(zip_file_path, row['study_id'], row['image_id'], row['xmin'], row['ymin'], row['xmax'], row['ymax'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the path to the ZIP file\n",
    "zip_file_path = 'D:\\\\Python files\\\\yolo_breast_cancer\\\\vindr-mammo-a-large-scale-benchmark-dataset-for-computer-aided-detection-and-diagnosis-in-full-field-digital-mammography-1.0.0.zip'\n",
    "\n",
    "# Function to load DICOM images from the ZIP file based on study_id and image_id\n",
    "def load_and_display_dicom_image(zip_file_path, study_id, image_id, xmin, ymin, xmax, ymax):\n",
    "    # Load the DICOM image from the ZIP file\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        with zip_ref.open(f'vindr-mammo-a-large-scale-benchmark-dataset-for-computer-aided-detection-and-diagnosis-in-full-field-digital-mammography-1.0.0/images/{study_id}/{image_id}.dicom') as file:\n",
    "            ds = pydicom.dcmread(file)\n",
    "\n",
    "    # Get the dimensions (width and height) of the DICOM image\n",
    "    width, height = ds.Columns, ds.Rows\n",
    "\n",
    "    # Rectify bounding box coordinates\n",
    "    xmin, ymin, xmax, ymax = max(0, xmin), max(0, ymin), max(0, xmax), max(0, ymax)\n",
    "\n",
    "    # Display the DICOM image with rectified bounding box and coordinates\n",
    "    plt.imshow(ds.pixel_array, cmap='gray')\n",
    "    plt.title(f'DICOM image from \"{image_id}.dicom\"\\nDimensions: {width} x {height}')\n",
    "\n",
    "    # Overlay rectified bounding box on the image\n",
    "    rect = plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, edgecolor='r', facecolor='none')\n",
    "    plt.gca().add_patch(rect)\n",
    "\n",
    "    # Display coordinates on top of the image\n",
    "    plt.text(xmin, ymin, f'({xmin}, {ymin})', color='r', fontsize=8, ha='left', va='top')\n",
    "    plt.text(xmax, ymax, f'({xmax}, {ymax})', color='r', fontsize=8, ha='right', va='bottom')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Assuming 'negative_values_df' contains rectified bounding box coordinates\n",
    "for index, row in negative_values_df.iterrows():\n",
    "    load_and_display_dicom_image(zip_file_path, row['study_id'], row['image_id'], row['xmin'], row['ymin'], row['xmax'], row['ymax'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your DataFrame is named 'data_final'\n",
    "# Make a copy of the original DataFrame\n",
    "corrected_data_final = data_final.copy()\n",
    "\n",
    "# Correct negative values in 'xmin', 'xmax', 'ymin', and 'ymax'\n",
    "corrected_data_final['xmin'] = corrected_data_final['xmin'].clip(lower=0)\n",
    "corrected_data_final['xmax'] = corrected_data_final['xmax'].clip(lower=0)\n",
    "corrected_data_final['ymin'] = corrected_data_final['ymin'].clip(lower=0)\n",
    "corrected_data_final['ymax'] = corrected_data_final['ymax'].clip(lower=0)\n",
    "\n",
    "# Check if there are still negative values\n",
    "negative_values_count = (\n",
    "    (corrected_data_final['xmin'] < 0).sum() +\n",
    "    (corrected_data_final['xmax'] < 0).sum() +\n",
    "    (corrected_data_final['ymin'] < 0).sum() +\n",
    "    (corrected_data_final['ymax'] < 0).sum()\n",
    ")\n",
    "\n",
    "print(\"Total count of rows with negative values after correction:\", negative_values_count)\n",
    "\n",
    "# Display the study_id, image_id, xmin, xmax, ymin, and ymax of rows with negative values\n",
    "negative_rows = corrected_data_final[\n",
    "    (corrected_data_final['xmin'] < 0) |\n",
    "    (corrected_data_final['xmax'] < 0) |\n",
    "    (corrected_data_final['ymin'] < 0) |\n",
    "    (corrected_data_final['ymax'] < 0)\n",
    "]\n",
    "\n",
    "print(\"DataFrame with rows containing negative values after correction:\")\n",
    "print(negative_rows[['study_id', 'image_id', 'xmin', 'xmax', 'ymin', 'ymax']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the desired number of malignant and benign images for the new dataset\n",
    "desired_malignant_count_new = 5000\n",
    "desired_benign_count_new = 5000\n",
    "\n",
    "# Create dataset_3 by sampling the desired number of malignant and benign images\n",
    "dataset_3 = corrected_data_final.copy()\n",
    "dataset_3['Oversampling'] = 0  # Adding the Oversampling column and setting initial values to 0\n",
    "\n",
    "# Sample the minimum between the desired count and the available count for malignant\n",
    "dataset_3_malignant = dataset_3[dataset_3['classification'] == 'Malignant']\n",
    "\n",
    "# Calculate the remaining counts needed for malignant\n",
    "remaining_malignant_count = desired_malignant_count_new - dataset_3_malignant.shape[0]\n",
    "\n",
    "# Oversample the malignant class to reach the desired count\n",
    "additional_malignant_duplicates = dataset_3[dataset_3['classification'] == 'Malignant'].sample(n=remaining_malignant_count, replace=True, random_state=42)\n",
    "additional_malignant_duplicates['Oversampling'] = 1\n",
    "\n",
    "# Sample the desired count for benign\n",
    "dataset_3_benign = dataset_3[dataset_3['classification'] == 'Benign'].sample(n=desired_benign_count_new, replace=True, random_state=42)\n",
    "dataset_3_benign['Oversampling'] = 0\n",
    "\n",
    "# Combine the selected malignant and benign cases to create the new dataset\n",
    "dataset_new = pd.concat([dataset_3_malignant, additional_malignant_duplicates, dataset_3_benign])\n",
    "\n",
    "# Display the total number of malignant and benign cases in the new dataset along with the \"Oversampling\" column\n",
    "classification_counts_new = dataset_new['classification'].value_counts()\n",
    "oversampling_counts = dataset_new['Oversampling'].value_counts()\n",
    "\n",
    "print(\"New Dataset:\")\n",
    "print(classification_counts_new)\n",
    "print(\"\\nOversampling Counts:\")\n",
    "print(oversampling_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your DataFrame is named 'dataset_new'\n",
    "# Make a copy of the original DataFrame\n",
    "dataset_new_copy = dataset_new.copy()\n",
    "\n",
    "# Handling NaN values in bounding box coordinates\n",
    "dataset_new_copy[['xmin', 'xmax', 'ymin', 'ymax']] = dataset_new_copy[['xmin', 'xmax', 'ymin', 'ymax']].fillna(0)\n",
    "\n",
    "# Convert bounding box coordinates to YOLO format for the copy\n",
    "dataset_new_copy['yolo_x'] = (dataset_new_copy['xmin'] + dataset_new_copy['xmax']) / (2 * dataset_new_copy['width'])\n",
    "dataset_new_copy['yolo_y'] = (dataset_new_copy['ymin'] + dataset_new_copy['ymax']) / (2 * dataset_new_copy['height'])\n",
    "dataset_new_copy['yolo_width'] = (dataset_new_copy['xmax'] - dataset_new_copy['xmin']) / dataset_new_copy['width']\n",
    "dataset_new_copy['yolo_height'] = (dataset_new_copy['ymax'] - dataset_new_copy['ymin']) / dataset_new_copy['height']\n",
    "\n",
    "# Display the YOLO bounding box values\n",
    "yolo_bbox_values = dataset_new_copy[['study_id', 'image_id', 'yolo_x', 'yolo_y', 'yolo_width', 'yolo_height']]\n",
    "print(\"YOLO Bounding Box Values:\")\n",
    "print(yolo_bbox_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if YOLO bounding box values are exactly within the range [0, 1]\n",
    "invalid_yolo_values = (\n",
    "    ~dataset_new_copy['yolo_x'].between(0.0, 1.0) |\n",
    "    ~dataset_new_copy['yolo_y'].between(0.0, 1.0) |\n",
    "    ~dataset_new_copy['yolo_width'].between(0.0, 1.0) |\n",
    "    ~dataset_new_copy['yolo_height'].between(0.0, 1.0)\n",
    ")\n",
    "\n",
    "# Display rows with invalid YOLO bounding box values\n",
    "invalid_yolo_rows = dataset_new_copy[invalid_yolo_values]\n",
    "print(\"Rows with invalid YOLO bounding box values:\")\n",
    "print(invalid_yolo_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if YOLO bounding box values are within the range [0, 1] with 10 decimal points precision\n",
    "decimal_points = 15\n",
    "tolerance = 10**(-decimal_points)\n",
    "\n",
    "invalid_yolo_values = (\n",
    "    (dataset_new_copy['yolo_x'].round(decimal_points) < 0) & (dataset_new_copy['yolo_x'].round(decimal_points) > 1) |\n",
    "    (dataset_new_copy['yolo_y'].round(decimal_points) < 0) & (dataset_new_copy['yolo_y'].round(decimal_points) > 1) |\n",
    "    (dataset_new_copy['yolo_width'].round(decimal_points) < 0) & (dataset_new_copy['yolo_width'].round(decimal_points) > 1) |\n",
    "    (dataset_new_copy['yolo_height'].round(decimal_points) < 0) & (dataset_new_copy['yolo_height'].round(decimal_points) > 1)\n",
    ")\n",
    "\n",
    "# Display rows with invalid YOLO bounding box values\n",
    "invalid_yolo_rows = dataset_new_copy[invalid_yolo_values]\n",
    "print(\"Rows with invalid YOLO bounding box values:\")\n",
    "print(invalid_yolo_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of rows in dataset_new: {dataset_new.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "import os\n",
    "import zipfile\n",
    "import pydicom\n",
    "import cv2\n",
    "import matplotlib.patches as patches\n",
    "from math import isnan\n",
    "\n",
    "# Define your dataset_new\n",
    "# dataset_new = ...\n",
    "\n",
    "zip_file_path = 'D:\\\\Python files\\\\yolo_breast_cancer\\\\vindr-mammo-a-large-scale-benchmark-dataset-for-computer-aided-detection-and-diagnosis-in-full-field-digital-mammography-1.0.0.zip'\n",
    "\n",
    "def load_and_transform_dicom_image(zip_file_path, study_id, image_id, output_image_dir, output_label_dir, original_bounding_boxes, image_number):\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "            with zip_ref.open(f'vindr-mammo-a-large-scale-benchmark-dataset-for-computer-aided-detection-and-diagnosis-in-full-field-digital-mammography-1.0.0/images/{study_id}/{image_id}.dicom') as file:\n",
    "                ds = pydicom.dcmread(file)\n",
    "\n",
    "        pixel_data = ds.pixel_array\n",
    "        min_pixel_value = pixel_data.min()\n",
    "        max_pixel_value = pixel_data.max()\n",
    "        pixel_data = ((pixel_data - min_pixel_value) / (max_pixel_value - min_pixel_value) * 255).astype(int)\n",
    "        pixel_data = cv2.convertScaleAbs(pixel_data)\n",
    "        pixel_data = cv2.cvtColor(pixel_data, cv2.COLOR_BGR2GRAY) if len(pixel_data.shape) == 3 else pixel_data\n",
    "        clahe = cv2.createCLAHE(clipLimit=30.0, tileGridSize=(8, 8))\n",
    "        pixel_data = clahe.apply(pixel_data)\n",
    "\n",
    "        for i in range(len(original_bounding_boxes)):\n",
    "            bbox_list = list(original_bounding_boxes[i])\n",
    "            bbox_list[2] = np.abs(bbox_list[2] - 0.5 / pixel_data.shape[0])\n",
    "            bbox_list[3] = np.abs(bbox_list[3] - 0.5 / pixel_data.shape[1])\n",
    "            original_bounding_boxes[i] = tuple(bbox_list)\n",
    "\n",
    "        # Check the value of 'upsampling'\n",
    "        if row['Oversampling'] == 1:\n",
    "            transform = A.Compose([\n",
    "                A.RandomRotate90(p=0.5),\n",
    "                A.Rotate(limit=(-60, 60), interpolation=cv2.INTER_LINEAR, border_mode=cv2.BORDER_CONSTANT, p=0.5),\n",
    "                A.Transpose(p=0.5),\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                A.VerticalFlip(p=0.5),\n",
    "                A.Resize(height=640, width=640, always_apply=True),\n",
    "            ], bbox_params={'format': 'pascal_voc'})\n",
    "\n",
    "            transformed = transform(image=pixel_data, bboxes=np.array(original_bounding_boxes, dtype=np.float32))\n",
    "            transformed_bboxes = transformed[\"bboxes\"]\n",
    "        else:\n",
    "            transform = A.Compose([\n",
    "                A.Resize(height=640, width=640, always_apply=True),\n",
    "            ], bbox_params={'format': 'pascal_voc'})\n",
    "\n",
    "            transformed = transform(image=pixel_data, bboxes=np.array(original_bounding_boxes, dtype=np.float32))\n",
    "            transformed_bboxes = transformed[\"bboxes\"]\n",
    "\n",
    "        study_id = row['study_id']\n",
    "        image_id = row['image_id']\n",
    "        classification = row['classification']\n",
    "        oversampling = row['Oversampling']\n",
    "\n",
    "        for bbox in transformed_bboxes:\n",
    "            yolo_format = convert_to_yolo_format(640, 640, bbox)\n",
    "            print(f\"YOLO Coordinates: {yolo_format}\")\n",
    "\n",
    "        image_file_name = f'{oversampling}_{classification}_{image_number}.png'\n",
    "        bbox_file_name = f'{oversampling}_{classification}_{image_number}.txt'\n",
    "\n",
    "        image_file_path = os.path.join(output_image_dir, image_file_name)\n",
    "        bbox_file_path = os.path.join(output_label_dir, bbox_file_name)\n",
    "\n",
    "        cv2.imwrite(image_file_path, transformed[\"image\"])\n",
    "\n",
    "        with open(bbox_file_path, 'w') as bbox_file:\n",
    "            for bbox in transformed_bboxes:\n",
    "                yolo_format = convert_to_yolo_format(640, 640, bbox)\n",
    "                bbox_file.write(yolo_format + \"\\n\")\n",
    "\n",
    "        return {\n",
    "            \"transformed_image\": transformed[\"image\"],\n",
    "            \"transformed_bboxes\": transformed_bboxes\n",
    "        }\n",
    "\n",
    "    except ValueError as ve:\n",
    "        print(f\"Error processing Study ID: {study_id}, Image ID: {image_id}\")\n",
    "        print(f\"Error message: {ve}\")\n",
    "        return {\n",
    "            \"study_id\": study_id,\n",
    "            \"image_id\": image_id\n",
    "        }\n",
    "\n",
    "def display_image_dimensions(transformed_image):\n",
    "    height, width = transformed_image.shape[:2]\n",
    "    print(f\"Transformed Image Dimensions: Height={height}, Width={width}\")\n",
    "\n",
    "def convert_to_yolo_format(image_width, image_height, bbox):\n",
    "    x_min, y_min, x_max, y_max, class_label = bbox\n",
    "    center_x = (x_min + x_max) / 2\n",
    "    center_y = (y_min + y_max) / 2\n",
    "    width = x_max - x_min\n",
    "    height = y_max - y_min\n",
    "    center_x /= image_width\n",
    "    center_y /= image_height\n",
    "    width /= image_width\n",
    "    height /= image_height\n",
    "    return f\"{class_label} {center_x} {center_y} {width} {height}\"\n",
    "\n",
    "error_images = []\n",
    "image_number_counter = 1\n",
    "\n",
    "for _, row in dataset_new.iterrows():\n",
    "    study_id = row['study_id']\n",
    "    image_id = row['image_id']\n",
    "    if row['classification'] == 'Malignant':\n",
    "        class_label = 1\n",
    "    else:\n",
    "        class_label = 0 \n",
    "\n",
    "    x_min = row['xmin']\n",
    "    y_min = row['ymin']\n",
    "    x_max = row['xmax']\n",
    "    y_max = row['ymax']\n",
    "    image_width = row['width']\n",
    "    image_height = row['height']\n",
    "\n",
    "    if isnan(x_min) or isnan(x_max) or isnan(y_min) or isnan(y_max):\n",
    "        x_min, y_min, x_max, y_max = 0, 0, image_width, image_height\n",
    "\n",
    "    original_bounding_boxes = [(x_min, y_min, x_max, y_max, class_label)]\n",
    "\n",
    "    output_image_directory = 'D:\\Python files\\yolo_breast_cancer\\dataset_new_images1'\n",
    "    output_label_directory = 'D:\\Python files\\yolo_breast_cancer\\dataset_new_labels1'\n",
    "    os.makedirs(output_image_directory, exist_ok=True)\n",
    "    os.makedirs(output_label_directory, exist_ok=True)\n",
    "\n",
    "    result = load_and_transform_dicom_image(zip_file_path, study_id, image_id, output_image_directory, output_label_directory, original_bounding_boxes, image_number_counter)\n",
    "    if result is not None and \"transformed_image\" in result and \"transformed_bboxes\" in result:\n",
    "        error_images.append(result)\n",
    "        # Display the transformed image dimensions\n",
    "        display_image_dimensions(result[\"transformed_image\"])\n",
    "\n",
    "    image_number_counter += 1\n",
    "\n",
    "print(\"Study ID and Image ID pairs for images with ValueError:\", error_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "import os\n",
    "import zipfile\n",
    "import pydicom\n",
    "import cv2\n",
    "import matplotlib.patches as patches\n",
    "from math import isnan\n",
    "\n",
    "# Define your dataset_new\n",
    "# dataset_new = ...\n",
    "\n",
    "zip_file_path = 'D:\\\\Python files\\\\yolo_breast_cancer\\\\vindr-mammo-a-large-scale-benchmark-dataset-for-computer-aided-detection-and-diagnosis-in-full-field-digital-mammography-1.0.0.zip'\n",
    "\n",
    "def load_and_transform_dicom_image(zip_file_path, study_id, image_id, output_image_dir, output_label_dir, original_bounding_boxes, image_number):\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "            with zip_ref.open(f'vindr-mammo-a-large-scale-benchmark-dataset-for-computer-aided-detection-and-diagnosis-in-full-field-digital-mammography-1.0.0/images/{study_id}/{image_id}.dicom') as file:\n",
    "                ds = pydicom.dcmread(file)\n",
    "\n",
    "        pixel_data = ds.pixel_array\n",
    "        min_pixel_value = pixel_data.min()\n",
    "        max_pixel_value = pixel_data.max()\n",
    "        pixel_data = ((pixel_data - min_pixel_value) / (max_pixel_value - min_pixel_value) * 255).astype(int)\n",
    "        pixel_data = cv2.convertScaleAbs(pixel_data)\n",
    "        pixel_data = cv2.cvtColor(pixel_data, cv2.COLOR_BGR2GRAY) if len(pixel_data.shape) == 3 else pixel_data\n",
    "        clahe = cv2.createCLAHE(clipLimit=30.0, tileGridSize=(8, 8))\n",
    "        pixel_data = clahe.apply(pixel_data)\n",
    "\n",
    "        for i in range(len(original_bounding_boxes)):\n",
    "            bbox_list = list(original_bounding_boxes[i])\n",
    "            bbox_list[2] = np.abs(bbox_list[2] - 0.5 / pixel_data.shape[0])\n",
    "            bbox_list[3] = np.abs(bbox_list[3] - 0.5 / pixel_data.shape[1])\n",
    "            original_bounding_boxes[i] = tuple(bbox_list)\n",
    "\n",
    "        # Check the value of 'upsampling'\n",
    "        if row['Oversampling'] == 1:\n",
    "            transform = A.Compose([\n",
    "                A.RandomRotate90(p=0.5),\n",
    "                A.Rotate(limit=(-60, 60), interpolation=cv2.INTER_LINEAR, border_mode=cv2.BORDER_CONSTANT, p=0.5),\n",
    "                A.Transpose(p=0.5),\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                A.VerticalFlip(p=0.5),\n",
    "            ], bbox_params={'format': 'pascal_voc'})\n",
    "\n",
    "        else:\n",
    "            transform = A.Compose([\n",
    "            ], bbox_params={'format': 'pascal_voc'})\n",
    "\n",
    "        transformed = transform(image=pixel_data, bboxes=np.array(original_bounding_boxes, dtype=np.float32))\n",
    "        transformed_bboxes = transformed[\"bboxes\"]\n",
    "\n",
    "        study_id = row['study_id']\n",
    "        image_id = row['image_id']\n",
    "        classification = row['classification']\n",
    "        oversampling = row['Oversampling']\n",
    "\n",
    "        for bbox in transformed_bboxes:\n",
    "            yolo_format = convert_to_yolo_format(pixel_data.shape[1], pixel_data.shape[0], bbox)\n",
    "            print(f\"YOLO Coordinates: {yolo_format}\")\n",
    "\n",
    "        image_file_name = f'{oversampling}_{classification}_{image_number}.png'\n",
    "        bbox_file_name = f'{oversampling}_{classification}_{image_number}.txt'\n",
    "\n",
    "        image_file_path = os.path.join(output_image_dir, image_file_name)\n",
    "        bbox_file_path = os.path.join(output_label_dir, bbox_file_name)\n",
    "\n",
    "        cv2.imwrite(image_file_path, transformed[\"image\"])\n",
    "\n",
    "        with open(bbox_file_path, 'w') as bbox_file:\n",
    "            for bbox in transformed_bboxes:\n",
    "                yolo_format = convert_to_yolo_format(pixel_data.shape[1], pixel_data.shape[0], bbox)\n",
    "                bbox_file.write(yolo_format + \"\\n\")\n",
    "\n",
    "        return {\n",
    "            \"transformed_image\": transformed[\"image\"],\n",
    "            \"transformed_bboxes\": transformed_bboxes\n",
    "        }\n",
    "\n",
    "    except ValueError as ve:\n",
    "        print(f\"Error processing Study ID: {study_id}, Image ID: {image_id}\")\n",
    "        print(f\"Error message: {ve}\")\n",
    "        return {\n",
    "            \"study_id\": study_id,\n",
    "            \"image_id\": image_id\n",
    "        }\n",
    "\n",
    "\n",
    "def display_image_dimensions(transformed_image):\n",
    "    height, width = transformed_image.shape[:2]\n",
    "    print(f\"Transformed Image Dimensions: Height={height}, Width={width}\")\n",
    "\n",
    "def convert_to_yolo_format(image_width, image_height, bbox):\n",
    "    x_min, y_min, x_max, y_max, class_label = bbox\n",
    "    center_x = (x_min + x_max) / 2\n",
    "    center_y = (y_min + y_max) / 2\n",
    "    width = x_max - x_min\n",
    "    height = y_max - y_min\n",
    "    center_x /= image_width\n",
    "    center_y /= image_height\n",
    "    width /= image_width\n",
    "    height /= image_height\n",
    "    return f\"{class_label} {center_x} {center_y} {width} {height}\"\n",
    "\n",
    "error_images = []\n",
    "image_number_counter = 1\n",
    "\n",
    "for _, row in dataset_new.iterrows():\n",
    "    study_id = row['study_id']\n",
    "    image_id = row['image_id']\n",
    "    if row['classification'] == 'Malignant':\n",
    "        class_label = 1\n",
    "    else:\n",
    "        class_label = 0 \n",
    "\n",
    "    x_min = row['xmin']\n",
    "    y_min = row['ymin']\n",
    "    x_max = row['xmax']\n",
    "    y_max = row['ymax']\n",
    "    image_width = row['width']\n",
    "    image_height = row['height']\n",
    "\n",
    "    if isnan(x_min) or isnan(x_max) or isnan(y_min) or isnan(y_max):\n",
    "        x_min, y_min, x_max, y_max = 0, 0, image_width, image_height\n",
    "\n",
    "    original_bounding_boxes = [(x_min, y_min, x_max, y_max, class_label)]\n",
    "\n",
    "    output_image_directory = 'D:\\Python files\\yolo_breast_cancer\\dataset_new_images1'\n",
    "    output_label_directory = 'D:\\Python files\\yolo_breast_cancer\\dataset_new_labels1'\n",
    "    os.makedirs(output_image_directory, exist_ok=True)\n",
    "    os.makedirs(output_label_directory, exist_ok=True)\n",
    "\n",
    "    result = load_and_transform_dicom_image(zip_file_path, study_id, image_id, output_image_directory, output_label_directory, original_bounding_boxes, image_number_counter)\n",
    "    if result is not None and \"transformed_image\" in result and \"transformed_bboxes\" in result:\n",
    "        error_images.append(result)\n",
    "        # Display the transformed image dimensions\n",
    "        display_image_dimensions(result[\"transformed_image\"])\n",
    "\n",
    "    image_number_counter += 1\n",
    "\n",
    "print(\"Study ID and Image ID pairs for images with ValueError:\", error_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "import os\n",
    "import zipfile\n",
    "import pydicom\n",
    "import cv2\n",
    "import matplotlib.patches as patches\n",
    "from math import isnan\n",
    "\n",
    "# Define your dataset_new\n",
    "# dataset_new = ...\n",
    "\n",
    "zip_file_path = 'D:\\\\Python files\\\\yolo_breast_cancer\\\\vindr-mammo-a-large-scale-benchmark-dataset-for-computer-aided-detection-and-diagnosis-in-full-field-digital-mammography-1.0.0.zip'\n",
    "\n",
    "def load_and_transform_dicom_image(zip_file_path, study_id, image_id, output_image_dir, output_label_dir, original_bounding_boxes, image_number):\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "            with zip_ref.open(f'vindr-mammo-a-large-scale-benchmark-dataset-for-computer-aided-detection-and-diagnosis-in-full-field-digital-mammography-1.0.0/images/{study_id}/{image_id}.dicom') as file:\n",
    "                ds = pydicom.dcmread(file)\n",
    "\n",
    "        pixel_data = ds.pixel_array\n",
    "        min_pixel_value = pixel_data.min()\n",
    "        max_pixel_value = pixel_data.max()\n",
    "        pixel_data = ((pixel_data - min_pixel_value) / (max_pixel_value - min_pixel_value) * 255).astype(int)\n",
    "        pixel_data = cv2.convertScaleAbs(pixel_data)\n",
    "        pixel_data = cv2.cvtColor(pixel_data, cv2.COLOR_BGR2GRAY) if len(pixel_data.shape) == 3 else pixel_data\n",
    "        clahe = cv2.createCLAHE(clipLimit=30.0, tileGridSize=(8, 8))\n",
    "        pixel_data = clahe.apply(pixel_data)\n",
    "\n",
    "        for i in range(len(original_bounding_boxes)):\n",
    "            bbox_list = list(original_bounding_boxes[i])\n",
    "            bbox_list[2] = np.abs(bbox_list[2] - 0.5 / pixel_data.shape[0])\n",
    "            bbox_list[3] = np.abs(bbox_list[3] - 0.5 / pixel_data.shape[1])\n",
    "            original_bounding_boxes[i] = tuple(bbox_list)\n",
    "\n",
    "      \n",
    "        transform = A.Compose([\n",
    "            A.Resize(height=640, width=640, always_apply=True),\n",
    "        ], bbox_params={'format': 'pascal_voc'})\n",
    "\n",
    "        transformed = transform(image=pixel_data, bboxes=np.array(original_bounding_boxes, dtype=np.float32))\n",
    "        transformed_bboxes = transformed[\"bboxes\"]\n",
    "        \n",
    "\n",
    "        study_id = row['study_id']\n",
    "        image_id = row['image_id']\n",
    "        classification = row['classification']\n",
    "        oversampling = row['Oversampling']\n",
    "\n",
    "        for bbox in transformed_bboxes:\n",
    "            yolo_format = convert_to_yolo_format(640, 640, bbox)\n",
    "            print(f\"YOLO Coordinates: {yolo_format}\")\n",
    "\n",
    "        image_file_name = f'{oversampling}_{classification}_{image_number}.png'\n",
    "        bbox_file_name = f'{oversampling}_{classification}_{image_number}.txt'\n",
    "\n",
    "        image_file_path = os.path.join(output_image_dir, image_file_name)\n",
    "        bbox_file_path = os.path.join(output_label_dir, bbox_file_name)\n",
    "\n",
    "        cv2.imwrite(image_file_path, transformed[\"image\"])\n",
    "\n",
    "        with open(bbox_file_path, 'w') as bbox_file:\n",
    "            for bbox in transformed_bboxes:\n",
    "                yolo_format = convert_to_yolo_format(640, 640, bbox)\n",
    "                bbox_file.write(yolo_format + \"\\n\")\n",
    "\n",
    "        return {\n",
    "            \"transformed_image\": transformed[\"image\"],\n",
    "            \"transformed_bboxes\": transformed_bboxes\n",
    "        }\n",
    "\n",
    "    except ValueError as ve:\n",
    "        print(f\"Error processing Study ID: {study_id}, Image ID: {image_id}\")\n",
    "        print(f\"Error message: {ve}\")\n",
    "        return {\n",
    "            \"study_id\": study_id,\n",
    "            \"image_id\": image_id\n",
    "        }\n",
    "\n",
    "def display_image_dimensions(transformed_image):\n",
    "    height, width = transformed_image.shape[:2]\n",
    "    print(f\"Transformed Image Dimensions: Height={height}, Width={width}\")\n",
    "\n",
    "def convert_to_yolo_format(image_width, image_height, bbox):\n",
    "    x_min, y_min, x_max, y_max, class_label = bbox\n",
    "    center_x = (x_min + x_max) / 2\n",
    "    center_y = (y_min + y_max) / 2\n",
    "    width = x_max - x_min\n",
    "    height = y_max - y_min\n",
    "    center_x /= image_width\n",
    "    center_y /= image_height\n",
    "    width /= image_width\n",
    "    height /= image_height\n",
    "    return f\"{class_label} {center_x} {center_y} {width} {height}\"\n",
    "\n",
    "error_images = []\n",
    "image_number_counter = 1\n",
    "\n",
    "def display_image_with_boxes(image, bboxes):\n",
    "    fig, ax = plt.subplots(1)\n",
    "    ax.imshow(image, cmap='gray')\n",
    "    for bbox in bboxes:\n",
    "        x_min, y_min, x_max, y_max, _ = bbox\n",
    "        width = x_max - x_min\n",
    "        height = y_max - y_min\n",
    "        rect = patches.Rectangle((x_min, y_min), width, height, linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "    plt.show()\n",
    "\n",
    "for _, row in dataset_new.iterrows():\n",
    "    study_id = row['study_id']\n",
    "    image_id = row['image_id']\n",
    "    if row['classification'] == 'Malignant':\n",
    "        class_label = 1\n",
    "    else:\n",
    "        class_label = 0 \n",
    "\n",
    "    x_min = row['xmin']\n",
    "    y_min = row['ymin']\n",
    "    x_max = row['xmax']\n",
    "    y_max = row['ymax']\n",
    "    image_width = row['width']\n",
    "    image_height = row['height']\n",
    "\n",
    "    if isnan(x_min) or isnan(x_max) or isnan(y_min) or isnan(y_max):\n",
    "        x_min, y_min, x_max, y_max = 0, 0, image_width, image_height\n",
    "\n",
    "    original_bounding_boxes = [(x_min, y_min, x_max, y_max, class_label)]\n",
    "\n",
    "    output_image_directory = 'D:\\Python files\\yolo_breast_cancer\\dataset_new_images'\n",
    "    output_label_directory = 'D:\\Python files\\yolo_breast_cancer\\dataset_new_labels'\n",
    "    os.makedirs(output_image_directory, exist_ok=True)\n",
    "    os.makedirs(output_label_directory, exist_ok=True)\n",
    "\n",
    "    result = load_and_transform_dicom_image(zip_file_path, study_id, image_id, output_image_directory, output_label_directory, original_bounding_boxes, image_number_counter)\n",
    "    if result is not None and \"transformed_image\" in result and \"transformed_bboxes\" in result:\n",
    "        error_images.append(result)\n",
    "        # Display the transformed image dimensions\n",
    "        display_image_dimensions(result[\"transformed_image\"])\n",
    "\n",
    "    image_number_counter += 1\n",
    "\n",
    "print(\"Study ID and Image ID pairs for images with ValueError:\", error_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "import os\n",
    "import zipfile\n",
    "import pydicom\n",
    "import cv2\n",
    "import matplotlib.patches as patches\n",
    "from math import isnan\n",
    "\n",
    "# Define your dataset_new\n",
    "# dataset_new = ...\n",
    "\n",
    "zip_file_path = 'D:\\\\Python files\\\\yolo_breast_cancer\\\\vindr-mammo-a-large-scale-benchmark-dataset-for-computer-aided-detection-and-diagnosis-in-full-field-digital-mammography-1.0.0.zip'\n",
    "\n",
    "def load_and_transform_dicom_image(zip_file_path, study_id, image_id, output_image_dir, output_label_dir, original_bounding_boxes, image_number):\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "            with zip_ref.open(f'vindr-mammo-a-large-scale-benchmark-dataset-for-computer-aided-detection-and-diagnosis-in-full-field-digital-mammography-1.0.0/images/{study_id}/{image_id}.dicom') as file:\n",
    "                ds = pydicom.dcmread(file)\n",
    "\n",
    "        pixel_data = ds.pixel_array\n",
    "        min_pixel_value = pixel_data.min()\n",
    "        max_pixel_value = pixel_data.max()\n",
    "        pixel_data = ((pixel_data - min_pixel_value) / (max_pixel_value - min_pixel_value) * 255).astype(int)\n",
    "        pixel_data = cv2.convertScaleAbs(pixel_data)\n",
    "        pixel_data = cv2.cvtColor(pixel_data, cv2.COLOR_BGR2GRAY) if len(pixel_data.shape) == 3 else pixel_data\n",
    "        clahe = cv2.createCLAHE(clipLimit=30.0, tileGridSize=(8, 8))\n",
    "        pixel_data = clahe.apply(pixel_data)\n",
    "\n",
    "        for i in range(len(original_bounding_boxes)):\n",
    "            bbox_list = list(original_bounding_boxes[i])\n",
    "            bbox_list[2] = np.abs(bbox_list[2] - 0.5 / pixel_data.shape[0])\n",
    "            bbox_list[3] = np.abs(bbox_list[3] - 0.5 / pixel_data.shape[1])\n",
    "            original_bounding_boxes[i] = tuple(bbox_list)\n",
    "\n",
    "      \n",
    "        transform = A.Compose([\n",
    "            A.Resize(height=700, width=700, always_apply=True),\n",
    "        ], bbox_params={'format': 'pascal_voc'})\n",
    "\n",
    "        transformed = transform(image=pixel_data, bboxes=np.array(original_bounding_boxes, dtype=np.float32))\n",
    "        transformed_bboxes = transformed[\"bboxes\"]\n",
    "        \n",
    "\n",
    "        study_id = row['study_id']\n",
    "        image_id = row['image_id']\n",
    "        classification = row['classification']\n",
    "        oversampling = row['Oversampling']\n",
    "\n",
    "        for bbox in transformed_bboxes:\n",
    "            yolo_format = convert_to_yolo_format(700, 700, bbox)\n",
    "            print(f\"YOLO Coordinates: {yolo_format}\")\n",
    "\n",
    "        image_file_name = f'{oversampling}_{classification}_{image_number}.png'\n",
    "        bbox_file_name = f'{oversampling}_{classification}_{image_number}.txt'\n",
    "\n",
    "        image_file_path = os.path.join(output_image_dir, image_file_name)\n",
    "        bbox_file_path = os.path.join(output_label_dir, bbox_file_name)\n",
    "\n",
    "        cv2.imwrite(image_file_path, transformed[\"image\"])\n",
    "\n",
    "        with open(bbox_file_path, 'w') as bbox_file:\n",
    "            for bbox in transformed_bboxes:\n",
    "                yolo_format = convert_to_yolo_format(700, 700, bbox)\n",
    "                bbox_file.write(yolo_format + \"\\n\")\n",
    "\n",
    "        return {\n",
    "            \"transformed_image\": transformed[\"image\"],\n",
    "            \"transformed_bboxes\": transformed_bboxes\n",
    "        }\n",
    "\n",
    "    except ValueError as ve:\n",
    "        print(f\"Error processing Study ID: {study_id}, Image ID: {image_id}\")\n",
    "        print(f\"Error message: {ve}\")\n",
    "        return {\n",
    "            \"study_id\": study_id,\n",
    "            \"image_id\": image_id\n",
    "        }\n",
    "\n",
    "def display_image_dimensions(transformed_image):\n",
    "    height, width = transformed_image.shape[:2]\n",
    "    print(f\"Transformed Image Dimensions: Height={height}, Width={width}\")\n",
    "\n",
    "def convert_to_yolo_format(image_width, image_height, bbox):\n",
    "    x_min, y_min, x_max, y_max, class_label = bbox\n",
    "    center_x = (x_min + x_max) / 2\n",
    "    center_y = (y_min + y_max) / 2\n",
    "    width = x_max - x_min\n",
    "    height = y_max - y_min\n",
    "    center_x /= image_width\n",
    "    center_y /= image_height\n",
    "    width /= image_width\n",
    "    height /= image_height\n",
    "    return f\"{class_label} {center_x} {center_y} {width} {height}\"\n",
    "\n",
    "error_images = []\n",
    "image_number_counter = 1\n",
    "\n",
    "def display_image_with_boxes(image, bboxes):\n",
    "    fig, ax = plt.subplots(1)\n",
    "    ax.imshow(image, cmap='gray')\n",
    "    for bbox in bboxes:\n",
    "        x_min, y_min, x_max, y_max, _ = bbox\n",
    "        width = x_max - x_min\n",
    "        height = y_max - y_min\n",
    "        rect = patches.Rectangle((x_min, y_min), width, height, linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "    plt.show()\n",
    "\n",
    "for _, row in dataset_new.iterrows():\n",
    "    study_id = row['study_id']\n",
    "    image_id = row['image_id']\n",
    "    if row['classification'] == 'Malignant':\n",
    "        class_label = 1\n",
    "    else:\n",
    "        class_label = 0 \n",
    "\n",
    "    x_min = row['xmin']\n",
    "    y_min = row['ymin']\n",
    "    x_max = row['xmax']\n",
    "    y_max = row['ymax']\n",
    "    image_width = row['width']\n",
    "    image_height = row['height']\n",
    "\n",
    "    if isnan(x_min) or isnan(x_max) or isnan(y_min) or isnan(y_max):\n",
    "        x_min, y_min, x_max, y_max = 0, 0, image_width, image_height\n",
    "\n",
    "    original_bounding_boxes = [(x_min, y_min, x_max, y_max, class_label)]\n",
    "\n",
    "    output_image_directory = 'D:\\Python files\\yolo_breast_cancer\\dataset_new_images1'\n",
    "    output_label_directory = 'D:\\Python files\\yolo_breast_cancer\\dataset_new_labels1'\n",
    "    os.makedirs(output_image_directory, exist_ok=True)\n",
    "    os.makedirs(output_label_directory, exist_ok=True)\n",
    "\n",
    "    result = load_and_transform_dicom_image(zip_file_path, study_id, image_id, output_image_directory, output_label_directory, original_bounding_boxes, image_number_counter)\n",
    "    if result is not None and \"transformed_image\" in result and \"transformed_bboxes\" in result:\n",
    "        error_images.append(result)\n",
    "        # Display the transformed image dimensions\n",
    "        display_image_dimensions(result[\"transformed_image\"])\n",
    "\n",
    "    image_number_counter += 1\n",
    "\n",
    "print(\"Study ID and Image ID pairs for images with ValueError:\", error_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "import os\n",
    "import zipfile\n",
    "import pydicom\n",
    "import cv2\n",
    "import matplotlib.patches as patches\n",
    "from math import isnan\n",
    "\n",
    "# Define your dataset_new\n",
    "# dataset_new = ...\n",
    "\n",
    "zip_file_path = 'D:\\\\Python files\\\\yolo_breast_cancer\\\\vindr-mammo-a-large-scale-benchmark-dataset-for-computer-aided-detection-and-diagnosis-in-full-field-digital-mammography-1.0.0.zip'\n",
    "\n",
    "def load_and_transform_dicom_image(zip_file_path, study_id, image_id, output_image_dir, output_label_dir, original_bounding_boxes, image_number):\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "            with zip_ref.open(f'vindr-mammo-a-large-scale-benchmark-dataset-for-computer-aided-detection-and-diagnosis-in-full-field-digital-mammography-1.0.0/images/{study_id}/{image_id}.dicom') as file:\n",
    "                ds = pydicom.dcmread(file)\n",
    "\n",
    "        pixel_data = ds.pixel_array\n",
    "        min_pixel_value = pixel_data.min()\n",
    "        max_pixel_value = pixel_data.max()\n",
    "        pixel_data = ((pixel_data - min_pixel_value) / (max_pixel_value - min_pixel_value) * 255).astype(int)\n",
    "        pixel_data = cv2.convertScaleAbs(pixel_data)\n",
    "        pixel_data = cv2.cvtColor(pixel_data, cv2.COLOR_BGR2GRAY) if len(pixel_data.shape) == 3 else pixel_data\n",
    "        clahe = cv2.createCLAHE(clipLimit=30.0, tileGridSize=(8, 8))\n",
    "        pixel_data = clahe.apply(pixel_data)\n",
    "\n",
    "        for i in range(len(original_bounding_boxes)):\n",
    "            bbox_list = list(original_bounding_boxes[i])\n",
    "            bbox_list[2] = np.abs(bbox_list[2] - 0.5 / pixel_data.shape[0])\n",
    "            bbox_list[3] = np.abs(bbox_list[3] - 0.5 / pixel_data.shape[1])\n",
    "            original_bounding_boxes[i] = tuple(bbox_list)\n",
    "\n",
    "      \n",
    "        transform = A.Compose([\n",
    "            A.Resize(height=640, width=640, always_apply=True),\n",
    "        ], bbox_params={'format': 'pascal_voc'})\n",
    "\n",
    "        transformed = transform(image=pixel_data, bboxes=np.array(original_bounding_boxes, dtype=np.float32))\n",
    "        transformed_bboxes = transformed[\"bboxes\"]\n",
    "        \n",
    "\n",
    "        study_id = row['study_id']\n",
    "        image_id = row['image_id']\n",
    "        classification = row['classification']\n",
    "        oversampling = row['Oversampling']\n",
    "\n",
    "        for bbox in transformed_bboxes:\n",
    "            yolo_format = convert_to_yolo_format(640, 640, bbox)\n",
    "            print(f\"YOLO Coordinates: {yolo_format}\")\n",
    "\n",
    "        image_file_name = f'{oversampling}_{classification}_{image_number}.png'\n",
    "        bbox_file_name = f'{oversampling}_{classification}_{image_number}.txt'\n",
    "\n",
    "        image_file_path = os.path.join(output_image_dir, image_file_name)\n",
    "        bbox_file_path = os.path.join(output_label_dir, bbox_file_name)\n",
    "\n",
    "        cv2.imwrite(image_file_path, transformed[\"image\"])\n",
    "\n",
    "        with open(bbox_file_path, 'w') as bbox_file:\n",
    "            for bbox in transformed_bboxes:\n",
    "                yolo_format = convert_to_yolo_format(640, 640, bbox)\n",
    "                bbox_file.write(yolo_format + \"\\n\")\n",
    "\n",
    "        return {\n",
    "            \"transformed_image\": transformed[\"image\"],\n",
    "            \"transformed_bboxes\": transformed_bboxes\n",
    "        }\n",
    "\n",
    "    except ValueError as ve:\n",
    "        print(f\"Error processing Study ID: {study_id}, Image ID: {image_id}\")\n",
    "        print(f\"Error message: {ve}\")\n",
    "        return {\n",
    "            \"study_id\": study_id,\n",
    "            \"image_id\": image_id\n",
    "        }\n",
    "\n",
    "def display_image_dimensions(transformed_image):\n",
    "    height, width = transformed_image.shape[:2]\n",
    "    print(f\"Transformed Image Dimensions: Height={height}, Width={width}\")\n",
    "\n",
    "def convert_to_yolo_format(image_width, image_height, bbox):\n",
    "    x_min, y_min, x_max, y_max, class_label = bbox\n",
    "    center_x = (x_min + x_max) / 2\n",
    "    center_y = (y_min + y_max) / 2\n",
    "    width = x_max - x_min\n",
    "    height = y_max - y_min\n",
    "    center_x /= image_width\n",
    "    center_y /= image_height\n",
    "    width /= image_width\n",
    "    height /= image_height\n",
    "    return f\"{class_label} {center_x} {center_y} {width} {height}\"\n",
    "\n",
    "error_images = []\n",
    "image_number_counter = 1\n",
    "\n",
    "def display_image_with_boxes(image, bboxes):\n",
    "    fig, ax = plt.subplots(1)\n",
    "    ax.imshow(image, cmap='gray')\n",
    "    for bbox in bboxes:\n",
    "        x_min, y_min, x_max, y_max, _ = bbox\n",
    "        width = x_max - x_min\n",
    "        height = y_max - y_min\n",
    "        rect = patches.Rectangle((x_min, y_min), width, height, linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "    plt.show()\n",
    "\n",
    "for _, row in dataset_new.iterrows():\n",
    "    study_id = row['study_id']\n",
    "    image_id = row['image_id']\n",
    "    if row['classification'] == 'Malignant':\n",
    "        class_label = 1\n",
    "    else:\n",
    "        class_label = 0 \n",
    "\n",
    "    x_min = row['xmin']\n",
    "    y_min = row['ymin']\n",
    "    x_max = row['xmax']\n",
    "    y_max = row['ymax']\n",
    "    image_width = row['width']\n",
    "    image_height = row['height']\n",
    "\n",
    "    if isnan(x_min) or isnan(x_max) or isnan(y_min) or isnan(y_max):\n",
    "        x_min, y_min, x_max, y_max = 0, 0, image_width, image_height\n",
    "\n",
    "    original_bounding_boxes = [(x_min, y_min, x_max, y_max, class_label)]\n",
    "\n",
    "    output_image_directory = 'D:\\Python files\\yolo_breast_cancer\\dataset_new_images'\n",
    "    output_label_directory = 'D:\\Python files\\yolo_breast_cancer\\dataset_new_labels'\n",
    "    os.makedirs(output_image_directory, exist_ok=True)\n",
    "    os.makedirs(output_label_directory, exist_ok=True)\n",
    "\n",
    "    result = load_and_transform_dicom_image(zip_file_path, study_id, image_id, output_image_directory, output_label_directory, original_bounding_boxes, image_number_counter)\n",
    "    if result is not None and \"transformed_image\" in result and \"transformed_bboxes\" in result:\n",
    "        error_images.append(result)\n",
    "        # Display the transformed image dimensions\n",
    "        display_image_dimensions(result[\"transformed_image\"])\n",
    "\n",
    "    image_number_counter += 1\n",
    "\n",
    "print(\"Study ID and Image ID pairs for images with ValueError:\", error_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "import os\n",
    "import zipfile\n",
    "import pydicom\n",
    "import cv2\n",
    "import matplotlib.patches as patches\n",
    "from math import isnan\n",
    "\n",
    "# Define your dataset_new\n",
    "# dataset_new = ...\n",
    "\n",
    "zip_file_path = 'D:\\\\Python files\\\\yolo_breast_cancer\\\\vindr-mammo-a-large-scale-benchmark-dataset-for-computer-aided-detection-and-diagnosis-in-full-field-digital-mammography-1.0.0.zip'\n",
    "\n",
    "def load_and_transform_dicom_image(zip_file_path, study_id, image_id, output_image_dir, output_label_dir, original_bounding_boxes, image_number, error_images_count):\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "            with zip_ref.open(f'vindr-mammo-a-large-scale-benchmark-dataset-for-computer-aided-detection-and-diagnosis-in-full-field-digital-mammography-1.0.0/images/{study_id}/{image_id}.dicom') as file:\n",
    "                ds = pydicom.dcmread(file)\n",
    "\n",
    "        pixel_data = ds.pixel_array\n",
    "        min_pixel_value = pixel_data.min()\n",
    "        max_pixel_value = pixel_data.max()\n",
    "        pixel_data = ((pixel_data - min_pixel_value) / (max_pixel_value - min_pixel_value) * 255).astype(int)\n",
    "        pixel_data = cv2.convertScaleAbs(pixel_data)\n",
    "        pixel_data = cv2.cvtColor(pixel_data, cv2.COLOR_BGR2GRAY) if len(pixel_data.shape) == 3 else pixel_data\n",
    "        clahe = cv2.createCLAHE(clipLimit=30.0, tileGridSize=(8, 8))\n",
    "        pixel_data = clahe.apply(pixel_data)\n",
    "\n",
    "        # Check the value of 'upsampling'\n",
    "        if row['Oversampling'] == 1:\n",
    "            transform = A.Compose([\n",
    "                A.RandomRotate90(p=0.5),\n",
    "                A.Rotate(limit=(-60, 60), interpolation=cv2.INTER_LINEAR, border_mode=cv2.BORDER_CONSTANT, p=0.5),\n",
    "                A.Transpose(p=0.5),\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                A.VerticalFlip(p=0.5),\n",
    "            ], bbox_params={'format': 'pascal_voc'})\n",
    "\n",
    "            transformed = transform(image=pixel_data, bboxes=np.array(original_bounding_boxes, dtype=np.float32))\n",
    "            transformed_bboxes = transformed[\"bboxes\"]\n",
    "        else:\n",
    "            transformed = {'image': pixel_data, 'bboxes': np.array(original_bounding_boxes, dtype=np.float32)}\n",
    "            transformed_bboxes = transformed[\"bboxes\"]\n",
    "\n",
    "        study_id = row['study_id']\n",
    "        image_id = row['image_id']\n",
    "        classification = row['classification']\n",
    "        oversampling = row['Oversampling']\n",
    "\n",
    "        for bbox in transformed_bboxes:\n",
    "            yolo_format = convert_to_yolo_format(pixel_data.shape[1], pixel_data.shape[0], bbox)\n",
    "            print(f\"YOLO Coordinates: {yolo_format}\")\n",
    "\n",
    "        image_file_name = f'{oversampling}_{classification}_{image_number}.png'\n",
    "        bbox_file_name = f'{oversampling}_{classification}_{image_number}.txt'\n",
    "\n",
    "        image_file_path = os.path.join(output_image_dir, image_file_name)\n",
    "        bbox_file_path = os.path.join(output_label_dir, bbox_file_name)\n",
    "\n",
    "        cv2.imwrite(image_file_path, transformed[\"image\"])\n",
    "\n",
    "        with open(bbox_file_path, 'w') as bbox_file:\n",
    "            for bbox in transformed_bboxes:\n",
    "                yolo_format = convert_to_yolo_format(pixel_data.shape[1], pixel_data.shape[0], bbox)\n",
    "                bbox_file.write(yolo_format + \"\\n\")\n",
    "\n",
    "        return {\n",
    "            \"transformed_image\": transformed[\"image\"],\n",
    "            \"transformed_bboxes\": transformed_bboxes,\n",
    "            \"error_images_count\": error_images_count\n",
    "        }\n",
    "\n",
    "    except (MemoryError, ValueError) as e:\n",
    "        if isinstance(e, MemoryError):\n",
    "            print(f\"Memory error encountered while processing Study ID: {study_id}, Image ID: {image_id}\")\n",
    "        elif isinstance(e, ValueError):\n",
    "            print(f\"Value error encountered while processing Study ID: {study_id}, Image ID: {image_id}\")\n",
    "            print(f\"Error message: {e}\")\n",
    "        return {\n",
    "            \"study_id\": study_id,\n",
    "            \"image_id\": image_id,\n",
    "            \"error_images_count\": error_images_count + 1\n",
    "        }\n",
    "\n",
    "\n",
    "def display_image_dimensions(transformed_image):\n",
    "    height, width = transformed_image.shape[:2]\n",
    "    print(f\"Transformed Image Dimensions: Height={height}, Width={width}\")\n",
    "\n",
    "def convert_to_yolo_format(image_width, image_height, bbox):\n",
    "    x_min, y_min, x_max, y_max, class_label = bbox\n",
    "    center_x = (x_min + x_max) / 2\n",
    "    center_y = (y_min + y_max) / 2\n",
    "    width = x_max - x_min\n",
    "    height = y_max - y_min\n",
    "    center_x /= image_width\n",
    "    center_y /= image_height\n",
    "    width /= image_width\n",
    "    height /= image_height\n",
    "    return f\"{class_label} {center_x} {center_y} {width} {height}\"\n",
    "\n",
    "error_images_count = 0\n",
    "image_number_counter = 1  # Define image_number_counter here\n",
    "for _, row in dataset_new.iterrows():\n",
    "    study_id = row['study_id']\n",
    "    image_id = row['image_id']\n",
    "    if row['classification'] == 'Malignant':\n",
    "        class_label = 1\n",
    "    else:\n",
    "        class_label = 0 \n",
    "\n",
    "    x_min = row['xmin']\n",
    "    y_min = row['ymin']\n",
    "    x_max = row['xmax']\n",
    "    y_max = row['ymax']\n",
    "    image_width = row['width']\n",
    "    image_height = row['height']\n",
    "\n",
    "    if isnan(x_min) or isnan(x_max) or isnan(y_min) or isnan(y_max):\n",
    "        x_min, y_min, x_max, y_max = 0, 0, image_width, image_height\n",
    "\n",
    "    original_bounding_boxes = [(x_min, y_min, x_max, y_max, class_label)]\n",
    "\n",
    "    output_image_directory = 'D:\\Python files\\yolo_breast_cancer\\dataset_new_images'\n",
    "    output_label_directory = 'D:\\Python files\\yolo_breast_cancer\\dataset_new_labels'\n",
    "    os.makedirs(output_image_directory, exist_ok=True)\n",
    "    os.makedirs(output_label_directory, exist_ok=True)\n",
    "\n",
    "    result = load_and_transform_dicom_image(zip_file_path, study_id, image_id, output_image_directory, output_label_directory, original_bounding_boxes, image_number_counter, error_images_count)\n",
    "    if result is not None and \"transformed_image\" in result and \"transformed_bboxes\" in result:\n",
    "        if \"error_images_count\" in result:\n",
    "            error_images_count = result[\"error_images_count\"]\n",
    "        else:\n",
    "            # Display the transformed image dimensions\n",
    "            display_image_dimensions(result[\"transformed_image\"])\n",
    "\n",
    "    image_number_counter += 1\n",
    "\n",
    "print(\"Total images with MemoryError:\", error_images_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "import os\n",
    "import zipfile\n",
    "import pydicom\n",
    "import cv2\n",
    "import matplotlib.patches as patches\n",
    "from math import isnan\n",
    "\n",
    "# Define your dataset_new\n",
    "# dataset_new = ...\n",
    "\n",
    "zip_file_path = 'D:\\\\Python files\\\\yolo_breast_cancer\\\\vindr-mammo-a-large-scale-benchmark-dataset-for-computer-aided-detection-and-diagnosis-in-full-field-digital-mammography-1.0.0.zip'\n",
    "\n",
    "def load_and_transform_dicom_image(zip_file_path, study_id, image_id, output_image_dir, output_label_dir, original_bounding_boxes, image_number, error_images_count):\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "            with zip_ref.open(f'vindr-mammo-a-large-scale-benchmark-dataset-for-computer-aided-detection-and-diagnosis-in-full-field-digital-mammography-1.0.0/images/{study_id}/{image_id}.dicom') as file:\n",
    "                ds = pydicom.dcmread(file)\n",
    "\n",
    "        pixel_data = ds.pixel_array\n",
    "        min_pixel_value = pixel_data.min()\n",
    "        max_pixel_value = pixel_data.max()\n",
    "        pixel_data = ((pixel_data - min_pixel_value) / (max_pixel_value - min_pixel_value) * 255).astype(int)\n",
    "        pixel_data = cv2.convertScaleAbs(pixel_data)\n",
    "        pixel_data = cv2.cvtColor(pixel_data, cv2.COLOR_BGR2GRAY) if len(pixel_data.shape) == 3 else pixel_data\n",
    "        clahe = cv2.createCLAHE(clipLimit=30.0, tileGridSize=(8, 8))\n",
    "        pixel_data = clahe.apply(pixel_data)\n",
    "\n",
    "        # Check the value of 'upsampling'\n",
    "        if row['Oversampling'] == 1:\n",
    "            transform = A.Compose([\n",
    "                A.RandomRotate90(p=0.5),\n",
    "                A.Rotate(limit=(-60, 60), interpolation=cv2.INTER_LINEAR, border_mode=cv2.BORDER_CONSTANT, p=0.5),\n",
    "                A.Transpose(p=0.5),\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                A.VerticalFlip(p=0.5),\n",
    "            ], bbox_params={'format': 'pascal_voc'})\n",
    "\n",
    "            transformed = transform(image=pixel_data, bboxes=np.array(original_bounding_boxes, dtype=np.float32))\n",
    "            transformed_bboxes = transformed[\"bboxes\"]\n",
    "        else:\n",
    "            transformed = {'image': pixel_data, 'bboxes': np.array(original_bounding_boxes, dtype=np.float32)}\n",
    "            transformed_bboxes = transformed[\"bboxes\"]\n",
    "\n",
    "        study_id = row['study_id']\n",
    "        image_id = row['image_id']\n",
    "        classification = row['classification']\n",
    "        oversampling = row['Oversampling']\n",
    "\n",
    "        for bbox in transformed_bboxes:\n",
    "            yolo_format = convert_to_yolo_format(ds.Rows, ds.Columns, bbox)  # Using original dimensions\n",
    "            print(f\"YOLO Coordinates: {yolo_format}\")\n",
    "\n",
    "        image_file_name = f'{oversampling}_{classification}_{image_number}.png'\n",
    "        bbox_file_name = f'{oversampling}_{classification}_{image_number}.txt'\n",
    "\n",
    "        image_file_path = os.path.join(output_image_dir, image_file_name)\n",
    "        bbox_file_path = os.path.join(output_label_dir, bbox_file_name)\n",
    "\n",
    "        cv2.imwrite(image_file_path, pixel_data)  # Save original size image\n",
    "\n",
    "        with open(bbox_file_path, 'w') as bbox_file:\n",
    "            for bbox in transformed_bboxes:\n",
    "                yolo_format = convert_to_yolo_format(ds.Rows, ds.Columns, bbox)  # Using original dimensions\n",
    "                bbox_file.write(yolo_format + \"\\n\")\n",
    "\n",
    "        return {\n",
    "            \"transformed_image\": pixel_data,\n",
    "            \"transformed_bboxes\": transformed_bboxes,\n",
    "            \"error_images_count\": error_images_count\n",
    "        }\n",
    "\n",
    "    except (MemoryError, ValueError) as e:\n",
    "        if isinstance(e, MemoryError):\n",
    "            print(f\"Memory error encountered while processing Study ID: {study_id}, Image ID: {image_id}\")\n",
    "        elif isinstance(e, ValueError):\n",
    "            print(f\"Value error encountered while processing Study ID: {study_id}, Image ID: {image_id}\")\n",
    "            print(f\"Error message: {e}\")\n",
    "        return {\n",
    "            \"study_id\": study_id,\n",
    "            \"image_id\": image_id,\n",
    "            \"error_images_count\": error_images_count + 1\n",
    "        }\n",
    "\n",
    "\n",
    "def display_image_dimensions(transformed_image):\n",
    "    height, width = transformed_image.shape[:2]\n",
    "    print(f\"Transformed Image Dimensions: Height={height}, Width={width}\")\n",
    "\n",
    "def convert_to_yolo_format(image_width, image_height, bbox):\n",
    "    x_min, y_min, x_max, y_max, class_label = bbox\n",
    "    center_x = (x_min + x_max) / 2\n",
    "    center_y = (y_min + y_max) / 2\n",
    "    width = x_max - x_min\n",
    "    height = y_max - y_min\n",
    "    center_x /= image_width\n",
    "    center_y /= image_height\n",
    "    width /= image_width\n",
    "    height /= image_height\n",
    "    return f\"{class_label} {center_x} {center_y} {width} {height}\"\n",
    "\n",
    "error_images_count = 0\n",
    "image_number_counter = 1  # Define image_number_counter here\n",
    "for _, row in dataset_new.iterrows():\n",
    "    study_id = row['study_id']\n",
    "    image_id = row['image_id']\n",
    "    if row['classification'] == 'Malignant':\n",
    "        class_label = 1\n",
    "    else:\n",
    "        class_label = 0 \n",
    "\n",
    "    x_min = row['xmin']\n",
    "    y_min = row['ymin']\n",
    "    x_max = row['xmax']\n",
    "    y_max = row['ymax']\n",
    "    image_width = row['width']\n",
    "    image_height = row['height']\n",
    "\n",
    "    if isnan(x_min) or isnan(x_max) or isnan(y_min) or isnan(y_max):\n",
    "        x_min, y_min, x_max, y_max = 0, 0, image_width, image_height\n",
    "\n",
    "    original_bounding_boxes = [(x_min, y_min, x_max, y_max, class_label)]\n",
    "\n",
    "    output_image_directory = 'D:\\Python files\\yolo_breast_cancer\\dataset_new_images'\n",
    "    output_label_directory = 'D:\\Python files\\yolo_breast_cancer\\dataset_new_labels'\n",
    "    os.makedirs(output_image_directory, exist_ok=True)\n",
    "    os.makedirs(output_label_directory, exist_ok=True)\n",
    "\n",
    "    result = load_and_transform_dicom_image(zip_file_path, study_id, image_id, output_image_directory, output_label_directory, original_bounding_boxes, image_number_counter, error_images_count)\n",
    "    if result is not None and \"transformed_image\" in result and \"transformed_bboxes\" in result:\n",
    "        if \"error_images_count\" in result:\n",
    "            error_images_count = result[\"error_images_count\"]\n",
    "        else:\n",
    "            # Display the transformed image dimensions\n",
    "            display_image_dimensions(result[\"transformed_image\"])\n",
    "\n",
    "    image_number_counter += 1\n",
    "\n",
    "print(\"Total images with MemoryError:\", error_images_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import zipfile\n",
    "import pydicom\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.patches as patches\n",
    "from math import isnan\n",
    "\n",
    "# Define your dataset_new\n",
    "# dataset_new = ...\n",
    "\n",
    "zip_file_path = 'D:/Python files/yolo_breast_cancer/vindr-mammo-a-large-scale-benchmark-dataset-for-computer-aided-detection-and-diagnosis-in-full-field-digital-mammography-1.0.0.zip'\n",
    "\n",
    "def load_and_transform_dicom_image(zip_file_path, study_id, image_id, output_image_dir, output_label_dir, original_bounding_boxes, image_number, error_images_count, row):\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "            with zip_ref.open(f'vindr-mammo-a-large-scale-benchmark-dataset-for-computer-aided-detection-and-diagnosis-in-full-field-digital-mammography-1.0.0/images/{study_id}/{image_id}.dicom') as file:\n",
    "                ds = pydicom.dcmread(file)\n",
    "\n",
    "        pixel_data = ds.pixel_array\n",
    "        min_pixel_value = pixel_data.min()\n",
    "        max_pixel_value = pixel_data.max()\n",
    "        pixel_data = ((pixel_data - min_pixel_value) / (max_pixel_value - min_pixel_value) * 255).astype(int)\n",
    "        pixel_data = cv2.convertScaleAbs(pixel_data)\n",
    "        pixel_data = cv2.cvtColor(pixel_data, cv2.COLOR_BGR2GRAY) if len(pixel_data.shape) == 3 else pixel_data\n",
    "        clahe = cv2.createCLAHE(clipLimit=30.0, tileGridSize=(8, 8))\n",
    "        pixel_data = clahe.apply(pixel_data)\n",
    "\n",
    "        # Resize the image to 1000x1000\n",
    "        pixel_data_resized = cv2.resize(pixel_data, (1000, 1000))\n",
    "\n",
    "        # Check the value of 'upsampling'\n",
    "        if row['Oversampling'] == 1:\n",
    "            transform = A.Compose([\n",
    "                A.RandomRotate90(p=0.5),\n",
    "                A.Rotate(limit=(-60, 60), interpolation=cv2.INTER_LINEAR, border_mode=cv2.BORDER_CONSTANT, p=0.5),\n",
    "                A.Transpose(p=0.5),\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                A.VerticalFlip(p=0.5),\n",
    "                A.Resize(height=640, width=640, always_apply=True),\n",
    "            ], bbox_params={'format': 'pascal_voc'})\n",
    "\n",
    "            transformed = transform(image=pixel_data_resized, bboxes=np.array(original_bounding_boxes, dtype=np.float32))\n",
    "            transformed_bboxes = transformed[\"bboxes\"]\n",
    "        else:\n",
    "            transform = A.Compose([\n",
    "                A.Resize(height=640, width=640, always_apply=True),\n",
    "            ], bbox_params={'format': 'pascal_voc'})\n",
    "\n",
    "            transformed = transform(image=pixel_data_resized, bboxes=np.array(original_bounding_boxes, dtype=np.float32))\n",
    "            transformed_bboxes = transformed[\"bboxes\"]\n",
    "\n",
    "        study_id = row['study_id']\n",
    "        image_id = row['image_id']\n",
    "        classification = row['classification']\n",
    "        oversampling = row['Oversampling']\n",
    "\n",
    "        for bbox in transformed_bboxes:\n",
    "            yolo_format = convert_to_yolo_format(640, 640, bbox)  # Bounding box data for 640x640\n",
    "            print(f\"YOLO Coordinates: {yolo_format}\")\n",
    "\n",
    "        image_file_name = f'{oversampling}_{classification}_{image_number}.png'\n",
    "        bbox_file_name = f'{oversampling}_{classification}_{image_number}.txt'\n",
    "\n",
    "        image_file_path = os.path.join(output_image_dir, image_file_name)\n",
    "        bbox_file_path = os.path.join(output_label_dir, bbox_file_name)\n",
    "\n",
    "        cv2.imwrite(image_file_path, pixel_data_resized)  # Store the resized image (1000x1000)\n",
    "\n",
    "        with open(bbox_file_path, 'w') as bbox_file:\n",
    "            for bbox in transformed_bboxes:\n",
    "                yolo_format = convert_to_yolo_format(640, 640, bbox)  # Bounding box data for 640x640\n",
    "                bbox_file.write(yolo_format + \"\\n\")\n",
    "\n",
    "        return {\n",
    "            \"transformed_image\": pixel_data_resized,\n",
    "            \"transformed_bboxes\": transformed_bboxes,\n",
    "            \"error_images_count\": error_images_count\n",
    "        }\n",
    "\n",
    "    except (MemoryError, ValueError) as e:\n",
    "        if isinstance(e, MemoryError):\n",
    "            print(f\"Memory error encountered while processing Study ID: {study_id}, Image ID: {image_id}\")\n",
    "        elif isinstance(e, ValueError):\n",
    "            print(f\"Value error encountered while processing Study ID: {study_id}, Image ID: {image_id}\")\n",
    "            print(f\"Error message: {e}\")\n",
    "        return {\n",
    "            \"study_id\": study_id,\n",
    "            \"image_id\": image_id,\n",
    "            \"error_images_count\": error_images_count + 1\n",
    "        }\n",
    "\n",
    "def display_image_dimensions(transformed_image):\n",
    "    height, width = transformed_image.shape[:2]\n",
    "    print(f\"Transformed Image Dimensions: Height={height}, Width={width}\")\n",
    "\n",
    "def convert_to_yolo_format(image_width, image_height, bbox):\n",
    "    x_min, y_min, x_max, y_max, class_label = bbox\n",
    "    center_x = (x_min + x_max) / 2\n",
    "    center_y = (y_min + y_max) / 2\n",
    "    width = x_max - x_min\n",
    "    height = y_max - y_min\n",
    "    center_x /= image_width\n",
    "    center_y /= image_height\n",
    "    width /= image_width\n",
    "    height /= image_height\n",
    "    return f\"{class_label} {center_x} {center_y} {width} {height}\"\n",
    "\n",
    "error_images_count = 0\n",
    "image_number_counter = 1  # Define the counter for image numbering\n",
    "\n",
    "# Assuming 'dataset_new' is defined somewhere\n",
    "for _, row in dataset_new.iterrows():\n",
    "    study_id = row['study_id']\n",
    "    image_id = row['image_id']\n",
    "    if row['classification'] == 'Malignant':\n",
    "        class_label = 1\n",
    "    else:\n",
    "        class_label = 0 \n",
    "\n",
    "    x_min = row['xmin']\n",
    "    y_min = row['ymin']\n",
    "    x_max = row['xmax']\n",
    "    y_max = row['ymax']\n",
    "    image_width = row['width']\n",
    "    image_height = row['height']\n",
    "\n",
    "    if isnan(x_min) or isnan(x_max) or isnan(y_min) or isnan(y_max):\n",
    "        x_min, y_min, x_max, y_max = 0, 0, image_width, image_height\n",
    "\n",
    "    original_bounding_boxes = [(x_min, y_min, x_max, y_max, class_label)]\n",
    "\n",
    "    output_image_directory = 'D:/Python files/yolo_breast_cancer/dataset_new_images'\n",
    "    output_label_directory = 'D:/Python files/yolo_breast_cancer/dataset_new_labels'\n",
    "    os.makedirs(output_image_directory, exist_ok=True)\n",
    "    os.makedirs(output_label_directory, exist_ok=True)\n",
    "\n",
    "    result = load_and_transform_dicom_image(zip_file_path, study_id, image_id, output_image_directory, output_label_directory, original_bounding_boxes, image_number_counter, error_images_count, row)\n",
    "    if result is not None and \"transformed_image\" in result and \"transformed_bboxes\" in result:\n",
    "        if \"error_images_count\" in result:\n",
    "            error_images_count = result[\"error_images_count\"]\n",
    "        else:\n",
    "            # Display the transformed image dimensions\n",
    "            display_image_dimensions(result[\"transformed_image\"])\n",
    "\n",
    "    image_number_counter += 1\n",
    "\n",
    "print(\"Total images with MemoryError:\", error_images_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(error_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Replace these paths with your actual image and annotation directories\n",
    "image_dir = \"D:\\Python files\\yolo_breast_cancer\\dataset_new_images\"\n",
    "annotation_dir = \"D:\\Python files\\yolo_breast_cancer\\dataset_new_labels\"\n",
    "\n",
    "# Read images and annotations\n",
    "images = [os.path.join(image_dir, x) for x in os.listdir(image_dir) if x.endswith(\".png\")]\n",
    "annotations = [os.path.join(annotation_dir, x) for x in os.listdir(annotation_dir) if x.endswith(\".txt\")]\n",
    "\n",
    "images.sort()\n",
    "annotations.sort()\n",
    "\n",
    "# Split the dataset into train-valid-test splits\n",
    "train_images, val_images, train_annotations, val_annotations = train_test_split(images, annotations, test_size=0.2, random_state=1)\n",
    "val_images, test_images, val_annotations, test_annotations = train_test_split(val_images, val_annotations, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the paths to create\n",
    "directories_to_create = [\n",
    "    'images/train',\n",
    "    'images/val',\n",
    "    'images/test',\n",
    "    'labels/train',\n",
    "    'labels/val',\n",
    "    'labels/test'\n",
    "]\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for directory in directories_to_create:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# Now you have created the required directories for train, val, and test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to move images \n",
    "def move_files_to_folder(list_of_files, destination_folder):\n",
    "    for f in list_of_files:\n",
    "        try:\n",
    "            # Create the destination folder if it doesn't exist\n",
    "            os.makedirs(destination_folder, exist_ok=True)\n",
    "            shutil.move(f, destination_folder)\n",
    "        except Exception as e:\n",
    "            print(f\"Error moving {f} to {destination_folder}: {e}\")\n",
    "            assert False\n",
    "\n",
    "# Move the splits into their folders\n",
    "move_files_to_folder(train_images, 'images/train')\n",
    "move_files_to_folder(val_images, 'images/val')\n",
    "move_files_to_folder(test_images, 'images/test')\n",
    "move_files_to_folder(train_annotations, 'labels/train')\n",
    "move_files_to_folder(val_annotations, 'labels/val')\n",
    "move_files_to_folder(test_annotations, 'labels/test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Replace these paths with your actual image and annotation directories\n",
    "image_dir = \"D:\\Python files\\yolo_breast_cancer\\dataset_new_images\"\n",
    "annotation_dir = \"D:\\Python files\\yolo_breast_cancer\\dataset_new_labels\"\n",
    "\n",
    "# Read images and annotations\n",
    "images = [os.path.join(image_dir, x) for x in os.listdir(image_dir) if x.endswith(\".png\")]\n",
    "annotations = [os.path.join(annotation_dir, x) for x in os.listdir(annotation_dir) if x.endswith(\".txt\")]\n",
    "\n",
    "images.sort()\n",
    "annotations.sort()\n",
    "\n",
    "# Define the target number of images per set\n",
    "target_images_per_set = 2000\n",
    "\n",
    "# Calculate the total number of sets needed\n",
    "num_sets = len(images) // target_images_per_set\n",
    "\n",
    "# If there are remaining images, create an additional set\n",
    "if len(images) % target_images_per_set > 0:\n",
    "    num_sets += 1\n",
    "\n",
    "# Split the dataset into sets with approximately 2000 images each\n",
    "image_sets = [images[i*target_images_per_set:(i+1)*target_images_per_set] for i in range(num_sets)]\n",
    "annotation_sets = [annotations[i*target_images_per_set:(i+1)*target_images_per_set] for i in range(num_sets)]\n",
    "\n",
    "# Display the number of sets\n",
    "print(f\"Number of sets: {num_sets}\")\n",
    "\n",
    "for i, (image_set, annotation_set) in enumerate(zip(image_sets, annotation_sets)):\n",
    "    print(f\"Set {i+1}: {len(image_set)} images\")\n",
    "    print(f\"Set {i+1}: {len(annotation_set)} labels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Replace these paths with your actual image and annotation directories\n",
    "image_dir = \"D:\\Python files\\yolo_breast_cancer\\dataset_new_images1\"\n",
    "annotation_dir = \"D:\\Python files\\yolo_breast_cancer\\dataset_new_labels1\"\n",
    "\n",
    "# Read images and annotations\n",
    "images = [os.path.join(image_dir, x) for x in os.listdir(image_dir) if x.endswith(\".png\")]\n",
    "annotations = [os.path.join(annotation_dir, x) for x in os.listdir(annotation_dir) if x.endswith(\".txt\")]\n",
    "\n",
    "images.sort()\n",
    "annotations.sort()\n",
    "\n",
    "# Define the target number of images per class per set\n",
    "target_images_per_class_per_set = 2000\n",
    "\n",
    "# Calculate the total number of sets needed\n",
    "num_sets = len(images) // (2 * target_images_per_class_per_set)\n",
    "\n",
    "# If there are remaining images, create an additional set\n",
    "if len(images) % (2 * target_images_per_class_per_set) > 0:\n",
    "    num_sets += 1\n",
    "\n",
    "# Split the dataset into sets with exactly 1000 images for each class in each set\n",
    "image_sets = [images[i*target_images_per_class_per_set:(i+1)*target_images_per_class_per_set] +\n",
    "              images[(i+num_sets)*target_images_per_class_per_set:(i+num_sets+1)*target_images_per_class_per_set]\n",
    "              for i in range(num_sets)]\n",
    "annotation_sets = [annotations[i*target_images_per_class_per_set:(i+1)*target_images_per_class_per_set] +\n",
    "                   annotations[(i+num_sets)*target_images_per_class_per_set:(i+num_sets+1)*target_images_per_class_per_set]\n",
    "                   for i in range(num_sets)]\n",
    "\n",
    "# Display the number of sets\n",
    "print(f\"Number of sets: {num_sets}\")\n",
    "\n",
    "for i, (image_set, annotation_set) in enumerate(zip(image_sets, annotation_sets)):\n",
    "    total_images = len(image_set)  # Total number of images in the set\n",
    "    print(f\"\\nSet {i+1}: {total_images} images in total\")\n",
    "\n",
    "    # Count the number of images for each class\n",
    "    benign_images = sum(1 for img in image_set if 'benign' in img.lower())\n",
    "    malignant_images = total_images - benign_images\n",
    "\n",
    "    print(f\"  - Benign: {benign_images} images\")\n",
    "    print(f\"  - Malignant: {malignant_images} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Replace these paths with your actual image and annotation directories\n",
    "image_dir = \"D:\\Python files\\yolo_breast_cancer\\dataset_new_images1\"\n",
    "annotation_dir = \"D:\\Python files\\yolo_breast_cancer\\dataset_new_labels1\"\n",
    "\n",
    "# Read images and annotations\n",
    "images = [os.path.join(image_dir, x) for x in os.listdir(image_dir) if x.endswith(\".png\")]\n",
    "annotations = [os.path.join(annotation_dir, x) for x in os.listdir(annotation_dir) if x.endswith(\".txt\")]\n",
    "\n",
    "images.sort()\n",
    "annotations.sort()\n",
    "\n",
    "# Define the target number of images per class per set\n",
    "target_images_per_class_per_set = 2000\n",
    "\n",
    "# Calculate the total number of sets needed\n",
    "num_sets = len(images) // (2 * target_images_per_class_per_set)\n",
    "\n",
    "# If there are remaining images, create an additional set\n",
    "if len(images) % (2 * target_images_per_class_per_set) > 0:\n",
    "    num_sets += 1\n",
    "\n",
    "# Split the dataset into sets with exactly 1000 images for each class in each set\n",
    "image_sets = [images[i*target_images_per_class_per_set:(i+1)*target_images_per_class_per_set] +\n",
    "              images[(i+num_sets)*target_images_per_class_per_set:(i+num_sets+1)*target_images_per_class_per_set]\n",
    "              for i in range(num_sets)]\n",
    "annotation_sets = [annotations[i*target_images_per_class_per_set:(i+1)*target_images_per_class_per_set] +\n",
    "                   annotations[(i+num_sets)*target_images_per_class_per_set:(i+num_sets+1)*target_images_per_class_per_set]\n",
    "                   for i in range(num_sets)]\n",
    "\n",
    "# Utility function to move images\n",
    "def move_files_to_folder(list_of_files, destination_folder):\n",
    "    for f in list_of_files:\n",
    "        try:\n",
    "            # Create the destination folder if it doesn't exist\n",
    "            os.makedirs(destination_folder, exist_ok=True)\n",
    "            shutil.move(f, destination_folder)\n",
    "        except Exception as e:\n",
    "            print(f\"Error moving {f} to {destination_folder}: {e}\")\n",
    "            assert False\n",
    "\n",
    "# Split each set into train, val, and test\n",
    "for i, (image_set, annotation_set) in enumerate(zip(image_sets, annotation_sets)):\n",
    "    train_images, test_images, train_annotations, test_annotations = train_test_split(image_set, annotation_set, test_size=0.2, random_state=1)\n",
    "    val_images, test_images, val_annotations, test_annotations = train_test_split(test_images, test_annotations, test_size=0.5, random_state=1)\n",
    "\n",
    "    # Create directories for each set and move files\n",
    "    directories_to_create = [\n",
    "        f'set_{i+1}/images/train',\n",
    "        f'set_{i+1}/images/val',\n",
    "        f'set_{i+1}/images/test',\n",
    "        f'set_{i+1}/labels/train',\n",
    "        f'set_{i+1}/labels/val',\n",
    "        f'set_{i+1}/labels/test'\n",
    "    ]\n",
    "\n",
    "    # Create directories if they don't exist\n",
    "    for directory in directories_to_create:\n",
    "        os.makedirs(os.path.join(directory), exist_ok=True)\n",
    "\n",
    "    # Move the splits into their folders\n",
    "    move_files_to_folder(train_images, f'set_{i+1}/images/train')\n",
    "    move_files_to_folder(val_images, f'set_{i+1}/images/val')\n",
    "    move_files_to_folder(test_images, f'set_{i+1}/images/test')\n",
    "    move_files_to_folder(train_annotations, f'set_{i+1}/labels/train')\n",
    "    move_files_to_folder(val_annotations, f'set_{i+1}/labels/val')\n",
    "    move_files_to_folder(test_annotations, f'set_{i+1}/labels/test')\n",
    "\n",
    "    # Display the number of images in each set\n",
    "    total_images = len(image_set)\n",
    "    benign_images = sum(1 for img in image_set if 'benign' in img.lower())\n",
    "    malignant_images = total_images - benign_images\n",
    "\n",
    "    print(f\"Set {i+1}: Total={total_images}, Benign={benign_images}, Malignant={malignant_images}, Train={len(train_images)}, Val={len(val_images)}, Test={len(test_images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in D:\\Python files\\yolo_breast_cancer\\dataset_new_images: 11941\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Directory path containing the images\n",
    "image_directory = r\"D:\\Python files\\yolo_breast_cancer\\dataset_new_images\"\n",
    "\n",
    "# List all files in the directory\n",
    "files = os.listdir(image_directory)\n",
    "\n",
    "# Filter files with .png extension\n",
    "image_files = [file for file in files if file.endswith('.png')]\n",
    "\n",
    "# Count the number of image files\n",
    "num_images = len(image_files)\n",
    "\n",
    "print(f\"Number of images in {image_directory}: {num_images}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in D:\\Python files\\yolo_breast_cancer\\dataset_new_labels: 11941\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Directory path containing the images\n",
    "image_directory = r\"D:\\Python files\\yolo_breast_cancer\\dataset_new_labels\"\n",
    "\n",
    "# List all files in the directory\n",
    "files = os.listdir(image_directory)\n",
    "\n",
    "# Filter files with .png extension\n",
    "image_files = [file for file in files if file.endswith('.txt')]\n",
    "\n",
    "# Count the number of image files\n",
    "num_images = len(image_files)\n",
    "\n",
    "print(f\"Number of images in {image_directory}: {num_images}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Load the image\n",
    "image_path = r''\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Get dimensions\n",
    "width, height = image.size\n",
    "\n",
    "print(\"Image dimensions: {} x {}\".format(width, height))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "# Replace 'D:\\Python files\\yolo_breast_cancer\\set_1\\images' with your actual folder path\n",
    "folder_path = r'D:\\Python files\\yolo_breast_cancer\\dataset_new_images'\n",
    "\n",
    "\n",
    "target_dimensions=(640, 640)\n",
    "\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            file_path = os.path.join(root, file)\n",
    "            with Image.open(file_path) as img:\n",
    "                if img.size != target_dimensions:\n",
    "                     print(f\"Image {file_path} does not have the expected dimensions of {target_dimensions}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y enum34 && pip install --upgrade pip setuptools wheel && apt-get update && apt-get install ffmpeg libsm6 libxext6  -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wandb --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r yolov5/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd D:\\Python files\\yolo_breast_cancer\\yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wandb login 2e91e350eab87cd7c9073e8040603c65b6bc7961"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --img 640 --epochs 50 --data set_1.yaml --weights yolov5m.pt --name yolo_vindr_12k --project yolo_vindr_12k_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image\n",
    "image_path = 'D:\\\\Python files\\\\yolo_breast_cancer\\\\12k\\\\images\\\\train\\\\0_Malignant_1.png'\n",
    "label_path = 'D:\\\\Python files\\\\yolo_breast_cancer\\\\12k\\\\labels\\\\train\\\\0_Malignant_1.txt'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Load the bounding box details\n",
    "with open(label_path, 'r') as file:\n",
    "    bounding_box_details = file.read().strip().split()\n",
    "\n",
    "# Extract bounding box coordinates\n",
    "x_center = float(bounding_box_details[1])\n",
    "y_center = float(bounding_box_details[2])\n",
    "width = float(bounding_box_details[3])\n",
    "height = float(bounding_box_details[4])\n",
    "\n",
    "# Calculate bounding box coordinates\n",
    "image_height, image_width, _ = image.shape\n",
    "x_min = int((x_center - width/2) * image_width)\n",
    "y_min = int((y_center - height/2) * image_height)\n",
    "x_max = int((x_center + width/2) * image_width)\n",
    "y_max = int((y_center + height/2) * image_height)\n",
    "\n",
    "# Draw bounding box on the image\n",
    "cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "\n",
    "# Display the image with bounding box\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image\n",
    "image_path = 'D:\\\\Python files\\\\yolo_breast_cancer\\\\12k\\\\images\\\\train\\\\0_Malignant_1.png'\n",
    "label_path = 'D:\\\\Python files\\\\yolo_breast_cancer\\\\12k\\\\labels\\\\train\\\\0_Malignant_1.txt'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Load the bounding box details\n",
    "with open(label_path, 'r') as file:\n",
    "    bounding_box_details = file.read().strip().split()\n",
    "\n",
    "# Extract bounding box coordinates\n",
    "x_center = float(bounding_box_details[1])\n",
    "y_center = float(bounding_box_details[2])\n",
    "width = float(bounding_box_details[3])\n",
    "height = float(bounding_box_details[4])\n",
    "\n",
    "# Original image size\n",
    "original_height, original_width, _ = image.shape\n",
    "\n",
    "# Scale factor for resizing the image while keeping the aspect ratio\n",
    "scale_factor = 400 / max(original_height, original_width)\n",
    "\n",
    "# New image size\n",
    "new_height = int(original_height * scale_factor)\n",
    "new_width = int(original_width * scale_factor)\n",
    "\n",
    "# Calculate bounding box coordinates for the new image size\n",
    "x_min = int((x_center - width/2) * original_width * scale_factor)\n",
    "y_min = int((y_center - height/2) * original_height * scale_factor)\n",
    "x_max = int((x_center + width/2) * original_width * scale_factor)\n",
    "y_max = int((y_center + height/2) * original_height * scale_factor)\n",
    "\n",
    "# Resize the image\n",
    "resized_image = cv2.resize(image, (new_width, new_height))\n",
    "\n",
    "# Draw bounding box on the resized image\n",
    "cv2.rectangle(resized_image, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "\n",
    "# Display the resized image with bounding box\n",
    "plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image and its corresponding bounding box details\n",
    "image_path = 'D:\\\\Python files\\\\yolo_breast_cancer\\\\12k\\\\images\\\\train\\\\0_Malignant_1.png'\n",
    "label_path = 'D:\\\\Python files\\\\yolo_breast_cancer\\\\12k\\\\labels\\\\train\\\\0_Malignant_1.txt'\n",
    "\n",
    "image = Image.open(image_path)\n",
    "original_image_width, original_image_height = image.size\n",
    "\n",
    "# Load bounding box details from the label file\n",
    "with open(label_path, 'r') as label_file:\n",
    "    lines = label_file.readlines()\n",
    "\n",
    "# Parse the bounding box coordinates\n",
    "bounding_boxes = []\n",
    "for line in lines:\n",
    "    data = line.strip().split()\n",
    "    class_label = int(float(data[0]))  # Convert float to int\n",
    "    x_center = float(data[1]) * original_image_width\n",
    "    y_center = float(data[2]) * original_image_height\n",
    "    box_width = float(data[3]) * original_image_width\n",
    "    box_height = float(data[4]) * original_image_height\n",
    "    \n",
    "    # Convert bounding box coordinates to (x_min, y_min, x_max, y_max) format\n",
    "    x_min = x_center - box_width / 2\n",
    "    y_min = y_center - box_height / 2\n",
    "    x_max = x_center + box_width / 2\n",
    "    y_max = y_center + box_height / 2\n",
    "    \n",
    "    bounding_boxes.append([x_min, y_min, x_max, y_max, class_label])\n",
    "\n",
    "# Define the augmentation pipeline\n",
    "transform = A.Compose([\n",
    "    A.RandomRotate90(),\n",
    "    A.HorizontalFlip(),\n",
    "    A.VerticalFlip(),\n",
    "    # Add more augmentations as needed\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', min_visibility=0.5))\n",
    "\n",
    "# Apply random augmentations to the image and bounding boxes\n",
    "augmented = transform(image=np.array(image), bboxes=np.array(bounding_boxes))\n",
    "\n",
    "# Adjust bounding box coordinates for the 400x400 view\n",
    "resized_bounding_boxes = []\n",
    "for bbox in augmented['bboxes']:\n",
    "    x_min, y_min, x_max, y_max, class_label = bbox\n",
    "    # Calculate scale factors for resizing bounding box coordinates\n",
    "    x_scale_factor = original_image_width / 400\n",
    "    y_scale_factor = original_image_height / 400\n",
    "    # Scale bounding box coordinates\n",
    "    x_min /= x_scale_factor\n",
    "    y_min /= y_scale_factor\n",
    "    x_max /= x_scale_factor\n",
    "    y_max /= y_scale_factor\n",
    "    resized_bounding_boxes.append([x_min, y_min, x_max, y_max, class_label])\n",
    "\n",
    "# Display the original image with the original bounding box details\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(image)\n",
    "for bbox in bounding_boxes:\n",
    "    x_min, y_min, x_max, y_max, class_label = bbox\n",
    "    width = x_max - x_min\n",
    "    height = y_max - y_min\n",
    "    plt.gca().add_patch(plt.Rectangle((x_min, y_min), width, height, fill=False, edgecolor='r', linewidth=2))\n",
    "plt.show()\n",
    "\n",
    "# Display the original image with the resized bounding box details (400x400 view)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(image)\n",
    "for bbox in resized_bounding_boxes:\n",
    "    x_min, y_min, x_max, y_max, class_label = bbox\n",
    "    width = x_max - x_min\n",
    "    height = y_max - y_min\n",
    "    plt.gca().add_patch(plt.Rectangle((x_min, y_min), width, height, fill=False, edgecolor='g', linewidth=2))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image and its corresponding bounding box details\n",
    "image_path = 'D:\\\\Python files\\\\yolo_breast_cancer\\\\12k\\\\images\\\\train\\\\0_Malignant_1.png'\n",
    "label_path = 'D:\\\\Python files\\\\yolo_breast_cancer\\\\12k\\\\labels\\\\train\\\\0_Malignant_1.txt'\n",
    "\n",
    "image = Image.open(image_path)\n",
    "original_image_width, original_image_height = image.size\n",
    "\n",
    "# Load bounding box details from the label file\n",
    "with open(label_path, 'r') as label_file:\n",
    "    lines = label_file.readlines()\n",
    "\n",
    "# Parse the bounding box coordinates\n",
    "bounding_boxes = []\n",
    "for line in lines:\n",
    "    data = line.strip().split()\n",
    "    class_label = int(float(data[0]))  # Convert float to int\n",
    "    x_center = float(data[1]) * original_image_width\n",
    "    y_center = float(data[2]) * original_image_height\n",
    "    box_width = float(data[3]) * original_image_width\n",
    "    box_height = float(data[4]) * original_image_height\n",
    "    \n",
    "    # Convert bounding box coordinates to (x_min, y_min, x_max, y_max) format\n",
    "    x_min = x_center - box_width / 2\n",
    "    y_min = y_center - box_height / 2\n",
    "    x_max = x_center + box_width / 2\n",
    "    y_max = y_center + box_height / 2\n",
    "    \n",
    "    bounding_boxes.append([x_min, y_min, x_max, y_max, class_label])\n",
    "\n",
    "# Define the augmentation pipeline\n",
    "transform = A.Compose([\n",
    "    A.RandomRotate90(),\n",
    "    A.HorizontalFlip(),\n",
    "    A.VerticalFlip(),\n",
    "    # Add more augmentations as needed\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', min_visibility=0.5))\n",
    "\n",
    "# Apply random augmentations to the image and bounding boxes\n",
    "augmented = transform(image=np.array(image), bboxes=np.array(bounding_boxes))\n",
    "\n",
    "# Adjust bounding box coordinates for the 400x400 view\n",
    "resized_bounding_boxes = []\n",
    "for bbox in augmented['bboxes']:\n",
    "    x_min, y_min, x_max, y_max, class_label = bbox\n",
    "    # Calculate scale factors for resizing bounding box coordinates\n",
    "    x_scale_factor = original_image_width / 400\n",
    "    y_scale_factor = original_image_height / 400\n",
    "    # Scale bounding box coordinates\n",
    "    x_min /= x_scale_factor\n",
    "    y_min /= y_scale_factor\n",
    "    x_max /= x_scale_factor\n",
    "    y_max /= y_scale_factor\n",
    "    resized_bounding_boxes.append([x_min, y_min, x_max, y_max, class_label])\n",
    "\n",
    "# Display the original image with the original bounding box details\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(image)\n",
    "for bbox in bounding_boxes:\n",
    "    x_min, y_min, x_max, y_max, class_label = bbox\n",
    "    width = x_max - x_min\n",
    "    height = y_max - y_min\n",
    "    plt.gca().add_patch(plt.Rectangle((x_min, y_min), width, height, fill=False, edgecolor='r', linewidth=2))\n",
    "plt.title('Original Image with Original Bounding Boxes')\n",
    "plt.show()\n",
    "\n",
    "# Display the original image with the resized bounding box details (400x400 view)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(image)\n",
    "for bbox in resized_bounding_boxes:\n",
    "    x_min, y_min, x_max, y_max, class_label = bbox\n",
    "    width = x_max - x_min\n",
    "    height = y_max - y_min\n",
    "    plt.gca().add_patch(plt.Rectangle((x_min, y_min), width, height, fill=False, edgecolor='g', linewidth=2))\n",
    "plt.title('Original Image with Resized Bounding Boxes (400x400 view)')\n",
    "plt.show()\n",
    "\n",
    "# Display the resized image with the resized bounding box details (400x400 view)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(augmented['image'])  # Use the augmented image here\n",
    "for bbox in resized_bounding_boxes:\n",
    "    x_min, y_min, x_max, y_max, class_label = bbox\n",
    "    width = x_max - x_min\n",
    "    height = y_max - y_min\n",
    "    plt.gca().add_patch(plt.Rectangle((x_min, y_min), width, height, fill=False, edgecolor='b', linewidth=2))\n",
    "plt.title('Resized Image with Resized Bounding Boxes (400x400 view)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "\n",
    "# Load the image and its corresponding bounding box details\n",
    "image_path = 'D:\\\\Python files\\\\yolo_breast_cancer\\\\12k\\\\images\\\\train\\\\0_Malignant_1.png'\n",
    "label_path = 'D:\\\\Python files\\\\yolo_breast_cancer\\\\12k\\\\labels\\\\train\\\\0_Malignant_1.txt'\n",
    "\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Load bounding box details from the label file\n",
    "with open(label_path, 'r') as label_file:\n",
    "    lines = label_file.readlines()\n",
    "\n",
    "# Parse the bounding box coordinates\n",
    "bounding_boxes = []\n",
    "for line in lines:\n",
    "    data = line.strip().split()\n",
    "    class_label = int(float(data[0]))  # Convert float to int\n",
    "    x_center = float(data[1]) * image.width\n",
    "    y_center = float(data[2]) * image.height\n",
    "    box_width = float(data[3]) * image.width\n",
    "    box_height = float(data[4]) * image.height\n",
    "    \n",
    "    # Convert bounding box coordinates to (x_min, y_min, x_max, y_max) format\n",
    "    x_min = x_center - box_width / 2\n",
    "    y_min = y_center - box_height / 2\n",
    "    x_max = x_center + box_width / 2\n",
    "    y_max = y_center + box_height / 2\n",
    "    \n",
    "    bounding_boxes.append([x_min, y_min, x_max, y_max, class_label])\n",
    "\n",
    "# Define the augmentation pipeline for the image\n",
    "image_transform = A.Compose([\n",
    "    A.RandomRotate90(),\n",
    "    A.HorizontalFlip(),\n",
    "    A.VerticalFlip(),\n",
    "    # Add more augmentations as needed\n",
    "])\n",
    "\n",
    "# Define the augmentation pipeline for the bounding boxes\n",
    "bbox_transform = A.Compose([\n",
    "    A.RandomRotate90(),\n",
    "    A.HorizontalFlip(),\n",
    "    A.VerticalFlip(),\n",
    "    A.Resize(height=640, width=640, always_apply=True)  # Add resize transformation\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', min_visibility=0.5))\n",
    "\n",
    "# Apply random augmentations to the image and bounding boxes\n",
    "augmented_image = image_transform(image=np.array(image))\n",
    "augmented_bbox = bbox_transform(image=augmented_image['image'], bboxes=np.array(bounding_boxes))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to display image with bounding boxes\n",
    "def visualize_bbox(image, bboxes):\n",
    "    image = image.copy()\n",
    "    for bbox in bboxes:\n",
    "        x_min, y_min, x_max, y_max, _ = bbox\n",
    "        x_min, y_min, x_max, y_max = int(x_min), int(y_min), int(x_max), int(y_max)\n",
    "        cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Display the augmented image\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(augmented_image['image'])\n",
    "plt.axis('off')\n",
    "plt.title('Augmented Image')\n",
    "plt.show()\n",
    "\n",
    "# Display the augmented bounding boxes on the augmented image\n",
    "visualize_bbox(augmented_image['image'], augmented_bbox['bboxes'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Define the paths to the image and label file\n",
    "image_path = 'D:\\\\Python files\\\\yolo_breast_cancer\\\\set_1\\\\images\\\\train\\\\0_Benign_10000.png'\n",
    "label_path = 'D:\\\\Python files\\\\yolo_breast_cancer\\\\set_1\\\\labels\\\\train\\\\0_Benign_10000.txt'\n",
    "\n",
    "# Load the image\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Display the image\n",
    "ax.imshow(image)\n",
    "\n",
    "# Read the bounding box coordinates from the label file\n",
    "with open(label_path, 'r') as label_file:\n",
    "    lines = label_file.readlines()\n",
    "\n",
    "# Parse the bounding box coordinates and draw rectangles\n",
    "for line in lines:\n",
    "    data = line.strip().split()\n",
    "    x_center = float(data[1]) * image.width\n",
    "    y_center = float(data[2]) * image.height\n",
    "    box_width = float(data[3]) * image.width\n",
    "    box_height = float(data[4]) * image.height\n",
    "    \n",
    "    x_min = x_center - box_width / 2\n",
    "    y_min = y_center - box_height / 2\n",
    "    \n",
    "    # Create a rectangle patch\n",
    "    rect = patches.Rectangle((x_min, y_min), box_width, box_height, linewidth=1, edgecolor='r', facecolor='none')\n",
    "    \n",
    "    # Add the rectangle to the axis\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
